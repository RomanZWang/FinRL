{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-LLC/FinRL-Library/blob/master/FinRL_ensemble_stock_trading_ICAIF_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading Using Ensemble Strategy\n",
    "\n",
    "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
    "\n",
    "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
    "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
    "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mPT0ipYE28wL"
   },
   "outputs": [],
   "source": [
    "# ## install finrl library\n",
    "# !pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EeMK7Uentj1V"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lPqeTTwoh1hn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.config import config\n",
    "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "from finrl.model.models import DRLAgent,DRLEnsembleAgent\n",
    "# from finrl.trade.backtest import get_baseline, backtest_stats, backtest_plot\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "87dea23f-469d-4e9d-de91-0f8a74929de2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2004-08-11'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py start_date is a string\n",
    "config.START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "d3baf63f-948a-49f9-f6f2-b7241971b8ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAPL', 'MSFT', 'JPM', 'RTX', 'PG', 'GS', 'NKE', 'DIS', 'AXP', 'HD', 'INTC', 'WMT', 'IBM', 'MRK', 'UNH', 'KO', 'CAT', 'TRV', 'JNJ', 'CVX', 'MCD', 'VZ', 'CSCO', 'XOM', 'BA', 'MMM', 'PFE', 'WBA', 'DD']\n"
     ]
    }
   ],
   "source": [
    "print(config.DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "932583d8-f98b-4243-c02d-375f7272db1a"
   },
   "outputs": [],
   "source": [
    "# from finrl.config.config import MISSING3\n",
    "# df = YahooDownloader(start_date = '2006-01-01',\n",
    "#                      end_date = '2021-06-11',\n",
    "#                      ticker_list = config.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.append(df2).append(df3).append(df4).append(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>2.585000</td>\n",
       "      <td>2.669643</td>\n",
       "      <td>2.580357</td>\n",
       "      <td>2.295634</td>\n",
       "      <td>807234400</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>51.700001</td>\n",
       "      <td>52.580002</td>\n",
       "      <td>51.049999</td>\n",
       "      <td>41.155041</td>\n",
       "      <td>7825700</td>\n",
       "      <td>AXP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>70.400002</td>\n",
       "      <td>70.599998</td>\n",
       "      <td>69.330002</td>\n",
       "      <td>50.119705</td>\n",
       "      <td>4943000</td>\n",
       "      <td>BA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>57.869999</td>\n",
       "      <td>58.110001</td>\n",
       "      <td>57.049999</td>\n",
       "      <td>38.086823</td>\n",
       "      <td>3697500</td>\n",
       "      <td>CAT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>17.209999</td>\n",
       "      <td>17.490000</td>\n",
       "      <td>17.180000</td>\n",
       "      <td>12.956775</td>\n",
       "      <td>55426000</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116020</th>\n",
       "      <td>116020</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>233.100006</td>\n",
       "      <td>234.259995</td>\n",
       "      <td>232.130005</td>\n",
       "      <td>233.949997</td>\n",
       "      <td>4452500</td>\n",
       "      <td>V</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116021</th>\n",
       "      <td>116021</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>57.330002</td>\n",
       "      <td>57.610001</td>\n",
       "      <td>57.220001</td>\n",
       "      <td>57.340000</td>\n",
       "      <td>12013600</td>\n",
       "      <td>VZ</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116022</th>\n",
       "      <td>116022</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>53.799999</td>\n",
       "      <td>55.580002</td>\n",
       "      <td>53.570000</td>\n",
       "      <td>55.310001</td>\n",
       "      <td>6638000</td>\n",
       "      <td>WBA</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116023</th>\n",
       "      <td>116023</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>139.080002</td>\n",
       "      <td>140.190002</td>\n",
       "      <td>139.080002</td>\n",
       "      <td>139.880005</td>\n",
       "      <td>5459500</td>\n",
       "      <td>WMT</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116024</th>\n",
       "      <td>116024</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>63.610001</td>\n",
       "      <td>63.980000</td>\n",
       "      <td>62.250000</td>\n",
       "      <td>62.750000</td>\n",
       "      <td>27488700</td>\n",
       "      <td>XOM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116025 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0        date        open        high         low  \\\n",
       "0                0  2006-01-03    2.585000    2.669643    2.580357   \n",
       "1                1  2006-01-03   51.700001   52.580002   51.049999   \n",
       "2                2  2006-01-03   70.400002   70.599998   69.330002   \n",
       "3                3  2006-01-03   57.869999   58.110001   57.049999   \n",
       "4                4  2006-01-03   17.209999   17.490000   17.180000   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "116020      116020  2021-06-10  233.100006  234.259995  232.130005   \n",
       "116021      116021  2021-06-10   57.330002   57.610001   57.220001   \n",
       "116022      116022  2021-06-10   53.799999   55.580002   53.570000   \n",
       "116023      116023  2021-06-10  139.080002  140.190002  139.080002   \n",
       "116024      116024  2021-06-10   63.610001   63.980000   62.250000   \n",
       "\n",
       "             close     volume   tic  day  \n",
       "0         2.295634  807234400  AAPL    1  \n",
       "1        41.155041    7825700   AXP    1  \n",
       "2        50.119705    4943000    BA    1  \n",
       "3        38.086823    3697500   CAT    1  \n",
       "4        12.956775   55426000  CSCO    1  \n",
       "...            ...        ...   ...  ...  \n",
       "116020  233.949997    4452500     V    3  \n",
       "116021   57.340000   12013600    VZ    3  \n",
       "116022   55.310001    6638000   WBA    3  \n",
       "116023  139.880005    5459500   WMT    3  \n",
       "116024   62.750000   27488700   XOM    3  \n",
       "\n",
       "[116025 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "# df.drop('Unnamed: 0')with open('dji_df_2004-2021.pkl', 'rb') as f:\n",
    "#     df = pickle.load(f)\n",
    "\n",
    "df = pd.read_csv('/home/roman/Work/trading-bot/notebooks/dji_prices_2020_04_09.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['date', 'tic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GiRuFOTOtj1Y",
    "outputId": "bf7071db-d71a-4e1b-a28f-8e0145e0d204"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>2.585000</td>\n",
       "      <td>2.669643</td>\n",
       "      <td>2.580357</td>\n",
       "      <td>2.295634</td>\n",
       "      <td>807234400</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>51.700001</td>\n",
       "      <td>52.580002</td>\n",
       "      <td>51.049999</td>\n",
       "      <td>41.155041</td>\n",
       "      <td>7825700</td>\n",
       "      <td>AXP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>70.400002</td>\n",
       "      <td>70.599998</td>\n",
       "      <td>69.330002</td>\n",
       "      <td>50.119705</td>\n",
       "      <td>4943000</td>\n",
       "      <td>BA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>57.869999</td>\n",
       "      <td>58.110001</td>\n",
       "      <td>57.049999</td>\n",
       "      <td>38.086823</td>\n",
       "      <td>3697500</td>\n",
       "      <td>CAT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>17.209999</td>\n",
       "      <td>17.490000</td>\n",
       "      <td>17.180000</td>\n",
       "      <td>12.956775</td>\n",
       "      <td>55426000</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       open       high        low      close     volume   tic  \\\n",
       "0  2006-01-03   2.585000   2.669643   2.580357   2.295634  807234400  AAPL   \n",
       "1  2006-01-03  51.700001  52.580002  51.049999  41.155041    7825700   AXP   \n",
       "2  2006-01-03  70.400002  70.599998  69.330002  50.119705    4943000    BA   \n",
       "3  2006-01-03  57.869999  58.110001  57.049999  38.086823    3697500   CAT   \n",
       "4  2006-01-03  17.209999  17.490000  17.180000  12.956775   55426000  CSCO   \n",
       "\n",
       "   day  \n",
       "0    1  \n",
       "1    1  \n",
       "2    1  \n",
       "3    1  \n",
       "4    1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DSw4ZEzVtj1Z",
    "outputId": "1a04171b-04c8-4974-9c63-3195261d8fd5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116020</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>233.100006</td>\n",
       "      <td>234.259995</td>\n",
       "      <td>232.130005</td>\n",
       "      <td>233.949997</td>\n",
       "      <td>4452500</td>\n",
       "      <td>V</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116021</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>57.330002</td>\n",
       "      <td>57.610001</td>\n",
       "      <td>57.220001</td>\n",
       "      <td>57.340000</td>\n",
       "      <td>12013600</td>\n",
       "      <td>VZ</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116022</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>53.799999</td>\n",
       "      <td>55.580002</td>\n",
       "      <td>53.570000</td>\n",
       "      <td>55.310001</td>\n",
       "      <td>6638000</td>\n",
       "      <td>WBA</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116023</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>139.080002</td>\n",
       "      <td>140.190002</td>\n",
       "      <td>139.080002</td>\n",
       "      <td>139.880005</td>\n",
       "      <td>5459500</td>\n",
       "      <td>WMT</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116024</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>63.610001</td>\n",
       "      <td>63.980000</td>\n",
       "      <td>62.250000</td>\n",
       "      <td>62.750000</td>\n",
       "      <td>27488700</td>\n",
       "      <td>XOM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date        open        high         low       close    volume  \\\n",
       "116020  2021-06-10  233.100006  234.259995  232.130005  233.949997   4452500   \n",
       "116021  2021-06-10   57.330002   57.610001   57.220001   57.340000  12013600   \n",
       "116022  2021-06-10   53.799999   55.580002   53.570000   55.310001   6638000   \n",
       "116023  2021-06-10  139.080002  140.190002  139.080002  139.880005   5459500   \n",
       "116024  2021-06-10   63.610001   63.980000   62.250000   62.750000  27488700   \n",
       "\n",
       "        tic  day  \n",
       "116020    V    3  \n",
       "116021   VZ    3  \n",
       "116022  WBA    3  \n",
       "116023  WMT    3  \n",
       "116024  XOM    3  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "b7b78172-8c8a-41c9-c8a6-0167edb9bd11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116025, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAPL', 'AXP', 'BA', 'CAT', 'CSCO', 'CVX', 'DD', 'DIS', 'GS', 'HD',\n",
       "       'IBM', 'INTC', 'JNJ', 'JPM', 'KO', 'MCD', 'MMM', 'MRK', 'MSFT',\n",
       "       'NKE', 'PFE', 'PG', 'RTX', 'TRV', 'UNH', 'VZ', 'WBA', 'WMT', 'XOM',\n",
       "       'V'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tic.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('dji_df_2004-2021.pkl', 'wb') as f:\n",
    "#     pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/roman/Work/trading-bot/notebooks/2004-2021_imputed_sentiment_final_df.pkl', 'rb') as f:\n",
    "    daily_sentiment_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'doc2vec_2004_2021_expanded_world_df.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b7847b9ba1bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'doc2vec_2004_2021_expanded_world_df.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdoc2vec_2004_2021_expanded_world_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'doc2vec_2004_2021_expanded_world_df.pkl'"
     ]
    }
   ],
   "source": [
    "with open('doc2vec_2004_2021_expanded_world_df.pkl', 'rb') as f:\n",
    "    doc2vec_2004_2021_expanded_world_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>business_score</th>\n",
       "      <th>environment_score</th>\n",
       "      <th>politics_score</th>\n",
       "      <th>science_score</th>\n",
       "      <th>technology_score</th>\n",
       "      <th>world_score</th>\n",
       "      <th>business_magnitude</th>\n",
       "      <th>environment_magnitude</th>\n",
       "      <th>politics_magnitude</th>\n",
       "      <th>science_magnitude</th>\n",
       "      <th>technology_magnitude</th>\n",
       "      <th>world_magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-08-11</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>-0.366667</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>3.500</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>10.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-08-12</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.366667</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>-0.233333</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>15.433333</td>\n",
       "      <td>19.966667</td>\n",
       "      <td>5.300</td>\n",
       "      <td>10.066666</td>\n",
       "      <td>13.033334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-08-13</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.233334</td>\n",
       "      <td>5.300</td>\n",
       "      <td>2.266667</td>\n",
       "      <td>19.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-08-14</td>\n",
       "      <td>-0.233333</td>\n",
       "      <td>-0.233333</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>5.300</td>\n",
       "      <td>7.533334</td>\n",
       "      <td>13.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-08-15</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>13.733334</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>5.300</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>5.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6141</th>\n",
       "      <td>2021-06-07</td>\n",
       "      <td>-0.152000</td>\n",
       "      <td>-0.111765</td>\n",
       "      <td>-0.313043</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>-0.208333</td>\n",
       "      <td>-0.226000</td>\n",
       "      <td>15.572000</td>\n",
       "      <td>10.935294</td>\n",
       "      <td>18.982609</td>\n",
       "      <td>6.175</td>\n",
       "      <td>14.133333</td>\n",
       "      <td>21.184000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6142</th>\n",
       "      <td>2021-06-08</td>\n",
       "      <td>-0.213793</td>\n",
       "      <td>-0.085714</td>\n",
       "      <td>-0.310526</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-0.238000</td>\n",
       "      <td>14.465517</td>\n",
       "      <td>12.633334</td>\n",
       "      <td>25.405263</td>\n",
       "      <td>6.100</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>19.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6143</th>\n",
       "      <td>2021-06-09</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.084211</td>\n",
       "      <td>-0.256000</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.234000</td>\n",
       "      <td>15.242857</td>\n",
       "      <td>11.794737</td>\n",
       "      <td>27.012000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>8.875000</td>\n",
       "      <td>18.166000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6144</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>-0.118519</td>\n",
       "      <td>-0.107692</td>\n",
       "      <td>-0.213636</td>\n",
       "      <td>-0.080000</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-0.178000</td>\n",
       "      <td>14.151852</td>\n",
       "      <td>11.176923</td>\n",
       "      <td>23.786363</td>\n",
       "      <td>6.260</td>\n",
       "      <td>19.525000</td>\n",
       "      <td>17.912000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6145</th>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>-0.091667</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-0.158824</td>\n",
       "      <td>12.233334</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>19.412500</td>\n",
       "      <td>5.400</td>\n",
       "      <td>31.650001</td>\n",
       "      <td>17.029412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6149 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  business_score  environment_score  politics_score  \\\n",
       "0     2004-08-11       -0.033333          -0.366667       -0.133333   \n",
       "1     2004-08-12       -0.166667          -0.100000       -0.366667   \n",
       "2     2004-08-13       -0.300000          -0.100000       -0.066667   \n",
       "3     2004-08-14       -0.233333          -0.233333       -0.300000   \n",
       "4     2004-08-15       -0.100000          -0.333333       -0.300000   \n",
       "...          ...             ...                ...             ...   \n",
       "6141  2021-06-07       -0.152000          -0.111765       -0.313043   \n",
       "6142  2021-06-08       -0.213793          -0.085714       -0.310526   \n",
       "6143  2021-06-09       -0.200000          -0.084211       -0.256000   \n",
       "6144  2021-06-10       -0.118519          -0.107692       -0.213636   \n",
       "6145  2021-06-11       -0.091667          -0.150000       -0.187500   \n",
       "\n",
       "      science_score  technology_score  world_score  business_magnitude  \\\n",
       "0          0.066667         -0.033333    -0.333333            4.533333   \n",
       "1         -0.100000         -0.066667    -0.233333            5.166667   \n",
       "2         -0.100000         -0.133333    -0.100000            3.833333   \n",
       "3         -0.100000          0.033333    -0.200000            9.400000   \n",
       "4         -0.100000         -0.050000    -0.333333            8.600000   \n",
       "...             ...               ...          ...                 ...   \n",
       "6141      -0.050000         -0.208333    -0.226000           15.572000   \n",
       "6142      -0.133333         -0.285714    -0.238000           14.465517   \n",
       "6143      -0.150000         -0.200000    -0.234000           15.242857   \n",
       "6144      -0.080000         -0.150000    -0.178000           14.151852   \n",
       "6145      -0.050000         -0.150000    -0.158824           12.233334   \n",
       "\n",
       "      environment_magnitude  politics_magnitude  science_magnitude  \\\n",
       "0                  9.400000           17.900000              3.500   \n",
       "1                 15.433333           19.966667              5.300   \n",
       "2                 13.000000           13.233334              5.300   \n",
       "3                 10.600000           16.100000              5.300   \n",
       "4                 13.733334           19.200000              5.300   \n",
       "...                     ...                 ...                ...   \n",
       "6141              10.935294           18.982609              6.175   \n",
       "6142              12.633334           25.405263              6.100   \n",
       "6143              11.794737           27.012000              7.000   \n",
       "6144              11.176923           23.786363              6.260   \n",
       "6145              15.100000           19.412500              5.400   \n",
       "\n",
       "      technology_magnitude  world_magnitude  \n",
       "0                 4.900000        10.100000  \n",
       "1                10.066666        13.033334  \n",
       "2                 2.266667        19.966667  \n",
       "3                 7.533334        13.933333  \n",
       "4                 7.200000         5.166667  \n",
       "...                    ...              ...  \n",
       "6141             14.133333        21.184000  \n",
       "6142             12.400000        19.104000  \n",
       "6143              8.875000        18.166000  \n",
       "6144             19.525000        17.912000  \n",
       "6145             31.650001        17.029412  \n",
       "\n",
       "[6149 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "jgXfBcjxtj1a",
    "outputId": "abf8d5bb-2cd2-4c12-d4cb-ed1c429e60ce",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = config.TECHNICAL_INDICATORS_LIST,\n",
    "                    use_turbulence=True)\n",
    "\n",
    "processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'open',\n",
       " 'high',\n",
       " 'low',\n",
       " 'close',\n",
       " 'volume',\n",
       " 'tic',\n",
       " 'day',\n",
       " 'macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma',\n",
       " 'turbulence']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(processed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "R_3v-ycktj1b"
   },
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "grvhGJJII3Xn",
    "outputId": "91d09c37-b0e9-4c5c-d532-967e40d11f41"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98384</th>\n",
       "      <td>2014-12-26</td>\n",
       "      <td>KO</td>\n",
       "      <td>42.970001</td>\n",
       "      <td>43.299999</td>\n",
       "      <td>42.930000</td>\n",
       "      <td>34.738411</td>\n",
       "      <td>6466900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.064256</td>\n",
       "      <td>36.556862</td>\n",
       "      <td>32.340991</td>\n",
       "      <td>53.046395</td>\n",
       "      <td>5.682230</td>\n",
       "      <td>4.699361</td>\n",
       "      <td>34.697113</td>\n",
       "      <td>34.382369</td>\n",
       "      <td>10.868352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30516</th>\n",
       "      <td>2008-10-16</td>\n",
       "      <td>DD</td>\n",
       "      <td>32.649807</td>\n",
       "      <td>34.770481</td>\n",
       "      <td>31.311934</td>\n",
       "      <td>23.545073</td>\n",
       "      <td>13451631.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.523777</td>\n",
       "      <td>37.212106</td>\n",
       "      <td>20.825833</td>\n",
       "      <td>35.990520</td>\n",
       "      <td>-159.802027</td>\n",
       "      <td>45.678783</td>\n",
       "      <td>30.571354</td>\n",
       "      <td>31.495738</td>\n",
       "      <td>258.958355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23422</th>\n",
       "      <td>2008-02-22</td>\n",
       "      <td>RTX</td>\n",
       "      <td>44.487099</td>\n",
       "      <td>45.588421</td>\n",
       "      <td>44.487099</td>\n",
       "      <td>33.022282</td>\n",
       "      <td>5890105.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.111093</td>\n",
       "      <td>33.873508</td>\n",
       "      <td>32.232612</td>\n",
       "      <td>48.317850</td>\n",
       "      <td>-0.900113</td>\n",
       "      <td>23.338690</td>\n",
       "      <td>32.740749</td>\n",
       "      <td>33.675688</td>\n",
       "      <td>27.158931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37814</th>\n",
       "      <td>2009-06-16</td>\n",
       "      <td>KO</td>\n",
       "      <td>24.094999</td>\n",
       "      <td>24.165001</td>\n",
       "      <td>23.910000</td>\n",
       "      <td>16.474377</td>\n",
       "      <td>15866200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.350705</td>\n",
       "      <td>17.278580</td>\n",
       "      <td>15.726889</td>\n",
       "      <td>57.563423</td>\n",
       "      <td>46.209978</td>\n",
       "      <td>17.541900</td>\n",
       "      <td>15.993804</td>\n",
       "      <td>15.519195</td>\n",
       "      <td>9.510180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133200</th>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>44.634998</td>\n",
       "      <td>44.945000</td>\n",
       "      <td>43.165001</td>\n",
       "      <td>42.138268</td>\n",
       "      <td>195208000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.548814</td>\n",
       "      <td>44.252927</td>\n",
       "      <td>36.561813</td>\n",
       "      <td>54.530359</td>\n",
       "      <td>65.676156</td>\n",
       "      <td>2.570460</td>\n",
       "      <td>40.775101</td>\n",
       "      <td>41.131040</td>\n",
       "      <td>46.914420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date   tic       open       high        low      close  \\\n",
       "98384   2014-12-26    KO  42.970001  43.299999  42.930000  34.738411   \n",
       "30516   2008-10-16    DD  32.649807  34.770481  31.311934  23.545073   \n",
       "23422   2008-02-22   RTX  44.487099  45.588421  44.487099  33.022282   \n",
       "37814   2009-06-16    KO  24.094999  24.165001  23.910000  16.474377   \n",
       "133200  2018-03-01  AAPL  44.634998  44.945000  43.165001  42.138268   \n",
       "\n",
       "             volume  day      macd    boll_ub    boll_lb     rsi_30  \\\n",
       "98384     6466900.0  4.0 -0.064256  36.556862  32.340991  53.046395   \n",
       "30516    13451631.0  3.0 -2.523777  37.212106  20.825833  35.990520   \n",
       "23422     5890105.0  4.0 -0.111093  33.873508  32.232612  48.317850   \n",
       "37814    15866200.0  1.0  0.350705  17.278580  15.726889  57.563423   \n",
       "133200  195208000.0  3.0  0.548814  44.252927  36.561813  54.530359   \n",
       "\n",
       "            cci_30      dx_30  close_30_sma  close_60_sma  turbulence  \n",
       "98384     5.682230   4.699361     34.697113     34.382369   10.868352  \n",
       "30516  -159.802027  45.678783     30.571354     31.495738  258.958355  \n",
       "23422    -0.900113  23.338690     32.740749     33.675688   27.158931  \n",
       "37814    46.209978  17.541900     15.993804     15.519195    9.510180  \n",
       "133200   65.676156   2.570460     40.775101     41.131040   46.914420  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2006-01-03'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full['date'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "187c6d1b-3e91-40f8-dafd-230d787f2ee1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.TECHNICAL_INDICATORS_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "8a2c943b-1be4-4b8d-b64f-666e0852b7e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 30, User Features: 0, State Space: 301\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(processed_full.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.TECHNICAL_INDICATORS_LIST)*stock_dimension + config.NUMBER_OF_DAILY_FEATURES\n",
    "print(f\"Stock Dimension: {stock_dimension}, User Features: {config.NUMBER_OF_USER_FEATURES}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 50_000_000/100, #Since in Indonesia the minimum number of shares per trx is 100, then we scaled the initial amount by dividing it with 100 \n",
    "    \"buy_cost_pct\": 0.0019, #IPOT has 0.19% buy cost\n",
    "    \"sell_cost_pct\": 0.0029, #IPOT has 0.29% sell cost\n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"print_verbosity\":5\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms.\n",
    "\n",
    "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "v-gthCxMtj1d"
   },
   "outputs": [],
   "source": [
    "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
    "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
    "train_start = '2006-01-03'\n",
    "train_end = '2016-01-01'\n",
    "val_test_start = '2016-01-01'\n",
    "val_test_end = '2021-06-11'\n",
    "\n",
    "ensemble_agent = DRLEnsembleAgent(df=processed_full,\n",
    "                 train_period=(train_start,train_end),\n",
    "                 val_test_period=(val_test_start,val_test_end),\n",
    "                 rebalance_window=rebalance_window, \n",
    "                 validation_window=validation_window,\n",
    "                 **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "KsfEHa_Etj1d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A2C_model_kwargs = {\n",
    "                    'n_steps': 5,\n",
    "                    'ent_coef': 0.01,\n",
    "                    'learning_rate': 0.0005\n",
    "                    }\n",
    "\n",
    "PPO_model_kwargs = {\n",
    "                    \"ent_coef\":0.01,\n",
    "                    \"n_steps\": 2048,\n",
    "                    \"learning_rate\": 0.00025,\n",
    "                    \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "DDPG_model_kwargs = {\n",
    "                      \"action_noise\":\"ornstein_uhlenbeck\",\n",
    "                      \"buffer_size\": 50_000,\n",
    "                      \"learning_rate\": 0.000005,\n",
    "                      \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "A2C2_model_kwargs = {\n",
    "                    'n_steps': 5,\n",
    "                    'ent_coef': 0.01,\n",
    "                    'learning_rate': 0.001\n",
    "                    }\n",
    "\n",
    "PPO2_model_kwargs = {\n",
    "                    \"ent_coef\":0.01,\n",
    "                    \"n_steps\": 2048,\n",
    "                    \"learning_rate\": 0.0005,\n",
    "                    \"batch_size\": 256\n",
    "                    }\n",
    "\n",
    "DDPG2_model_kwargs = {\n",
    "                      \"action_noise\":\"ornstein_uhlenbeck\",\n",
    "                      \"buffer_size\": 50_000,\n",
    "                      \"learning_rate\": 0.00001,\n",
    "                      \"batch_size\": 256\n",
    "                    }\n",
    "\n",
    "timesteps_dict = {'a2c' : 50_000, \n",
    "                 'ppo' : 50_000, \n",
    "                 'ddpg' : 25_000,\n",
    "                  'a2c2' : 25_000, \n",
    "                 'ppo2' : 25_000, \n",
    "                 'ddpg2' : 12_000\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1lyCECstj1e",
    "outputId": "72ac1ecc-909e-4d4c-d724-d906d7881ed9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Start Ensemble Strategy============\n",
      "============================================\n",
      "39.25064963834649\n",
      "turbulence_threshold:  458.4056541260132\n",
      "======Model training from:  2006-01-03 to  2016-01-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_126_19\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0426   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -10.7    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.569    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.387   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -32.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.584    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.608   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -25.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.336   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.954    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0765   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.00994  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 16.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.232    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.92e+05 |\n",
      "|    total_cost         | 1.82e+05 |\n",
      "|    total_reward       | 9.22e+04 |\n",
      "|    total_reward_pct   | 18.4     |\n",
      "|    total_trades       | 54320    |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.373   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -1.32    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0192   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -13.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.297    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.13    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -22.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.968    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.117    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 16.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.274    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0753  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 46.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.68e+05 |\n",
      "|    total_cost         | 2.55e+05 |\n",
      "|    total_reward       | 2.68e+05 |\n",
      "|    total_reward_pct   | 53.6     |\n",
      "|    total_trades       | 58057    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.00158 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -35.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -23.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.564    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.00235 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 33.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.855    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.431    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 43.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.01     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -2.24e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -4.11     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.11      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.27e+05 |\n",
      "|    total_cost         | 1.39e+05 |\n",
      "|    total_reward       | 2.27e+05 |\n",
      "|    total_reward_pct   | 45.4     |\n",
      "|    total_trades       | 53014    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.396   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 26.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.435    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -61.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.00338  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 28.3     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -91.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -109     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.78     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.69e+05  |\n",
      "|    total_cost         | 1.25e+05  |\n",
      "|    total_reward       | 4.69e+05  |\n",
      "|    total_reward_pct   | 93.7      |\n",
      "|    total_trades       | 53637     |\n",
      "| time/                 |           |\n",
      "|    fps                | 148       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 70        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -3.05e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 32.2      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.773     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | -0.0153  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 36.8     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.965    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -3.82    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.534    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.0241   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 18.6     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.451    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.078   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -237     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 38.1     |\n",
      "------------------------------------\n",
      "day: 2516, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 968608.35\n",
      "total_reward: 468608.35\n",
      "total_cost: 61841.96\n",
      "total_trades: 49600\n",
      "Sharpe: 0.398\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.69e+05 |\n",
      "|    total_cost         | 6.18e+04 |\n",
      "|    total_reward       | 4.69e+05 |\n",
      "|    total_reward_pct   | 93.7     |\n",
      "|    total_trades       | 49600    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.199   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 17.4     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.386    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -9.27    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.133    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | -0.0396  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -38.1    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.78     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0.0771   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 8.47     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 60       |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.27e+06 |\n",
      "|    total_cost         | 4.34e+04 |\n",
      "|    total_reward       | 7.67e+05 |\n",
      "|    total_reward_pct   | 153      |\n",
      "|    total_trades       | 47305    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -72.3    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.99     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | -1.04    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -47.3    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -25      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.538    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 21       |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.406    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 148       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 117       |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | -7.37     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.768     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.37e+06 |\n",
      "|    total_cost         | 2.25e+04 |\n",
      "|    total_reward       | 8.74e+05 |\n",
      "|    total_reward_pct   | 175      |\n",
      "|    total_trades       | 46952    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 24.4     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.354    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 148       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 124       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 15.6      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.376     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 28.3     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.519    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 148       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 131       |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 35.2      |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.748     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -16.8    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.264    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.37e+06 |\n",
      "|    total_cost         | 1.31e+04 |\n",
      "|    total_reward       | 8.68e+05 |\n",
      "|    total_reward_pct   | 174      |\n",
      "|    total_trades       | 46117    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | -0.146   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -46      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0.00563  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 44.9     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.21     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -48.3    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -80.4    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 3.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 25.3     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.4e+06  |\n",
      "|    total_cost         | 1.15e+04 |\n",
      "|    total_reward       | 9.02e+05 |\n",
      "|    total_reward_pct   | 180      |\n",
      "|    total_trades       | 47029    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -20.4    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.306    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 3.99     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.233    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 148       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 161       |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 19.5      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.329     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 43.9     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 33       |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.85     |\n",
      "------------------------------------\n",
      "day: 2516, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1595827.25\n",
      "total_reward: 1095827.25\n",
      "total_cost: 10879.49\n",
      "total_trades: 44487\n",
      "Sharpe: 0.733\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.6e+06   |\n",
      "|    total_cost         | 1.09e+04  |\n",
      "|    total_reward       | 1.1e+06   |\n",
      "|    total_reward_pct   | 219       |\n",
      "|    total_trades       | 44487     |\n",
      "| time/                 |           |\n",
      "|    fps                | 148       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 171       |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | -0.000279 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | 23.9      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.473     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 9        |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.254    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 3.63     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.313    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -48.7    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 13.6     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.613    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.65e+06 |\n",
      "|    total_cost         | 1.05e+04 |\n",
      "|    total_reward       | 1.15e+06 |\n",
      "|    total_reward_pct   | 230      |\n",
      "|    total_trades       | 43790    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -8.15    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.113    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 35.7     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.876    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -111     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 7        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -39.5    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.956    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -177     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 16.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.56e+06 |\n",
      "|    total_cost         | 1.08e+04 |\n",
      "|    total_reward       | 1.06e+06 |\n",
      "|    total_reward_pct   | 212      |\n",
      "|    total_trades       | 44106    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0.176    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -62.1    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 2.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -35.4    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.967    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 148       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 212       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | 49.5      |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 1.44      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | -169     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 16.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 95       |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 5.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.29e+06 |\n",
      "|    total_cost         | 9.23e+03 |\n",
      "|    total_reward       | 7.91e+05 |\n",
      "|    total_reward_pct   | 158      |\n",
      "|    total_trades       | 44677    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -2.76    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.0262   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 225      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -44.7    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 6.33     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.124    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 148       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 232       |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | -11.3     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.314     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -80.3    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 4.65     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.2e+06   |\n",
      "|    total_cost         | 8.39e+03  |\n",
      "|    total_reward       | 7.03e+05  |\n",
      "|    total_reward_pct   | 141       |\n",
      "|    total_trades       | 44119     |\n",
      "| time/                 |           |\n",
      "|    fps                | 148       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 239       |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | -5.96     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.0539    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 33.1     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 246      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 0.377    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.0584   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | -0.146   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -66.1    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 2.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 253      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | -0.00169 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 101      |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 8.26     |\n",
      "------------------------------------\n",
      "day: 2516, episode: 15\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1151166.50\n",
      "total_reward: 651166.50\n",
      "total_cost: 8596.55\n",
      "total_trades: 43163\n",
      "Sharpe: 0.560\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.15e+06 |\n",
      "|    total_cost         | 8.6e+03  |\n",
      "|    total_reward       | 6.51e+05 |\n",
      "|    total_reward_pct   | 130      |\n",
      "|    total_trades       | 43163    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 256      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 25.3     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.312    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 260      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 35.8     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 1.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 263      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | -0.14    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 27.3     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 1.41     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 266       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | 18.2      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.512     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 270      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 4.69     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.377    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.1e+06  |\n",
      "|    total_cost         | 6.93e+03 |\n",
      "|    total_reward       | 6.04e+05 |\n",
      "|    total_reward_pct   | 121      |\n",
      "|    total_trades       | 42275    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 273      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 0.395    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.00801  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 276      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -27.3    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 2.71     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 148       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 280       |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.7     |\n",
      "|    explained_variance | -0.000326 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | 12.3      |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.295     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 283      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 22.5     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.67     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 287      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 129      |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 8        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.24e+06 |\n",
      "|    total_cost         | 7.02e+03 |\n",
      "|    total_reward       | 7.42e+05 |\n",
      "|    total_reward_pct   | 148      |\n",
      "|    total_trades       | 42439    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 290      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.8    |\n",
      "|    explained_variance | -0.216   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 21.3     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 293      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -68.5    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 4.24     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 297       |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | 20.6      |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.206     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 300      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | -98.7    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 4.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 304      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 113      |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 6.95     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.16e+06 |\n",
      "|    total_cost         | 6.68e+03 |\n",
      "|    total_reward       | 6.58e+05 |\n",
      "|    total_reward_pct   | 132      |\n",
      "|    total_trades       | 43310    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 307      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | -16.3    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.147    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 311       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | -114      |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 6.34      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 314      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -9.76    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.183    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 318      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 70.9     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 3.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 321      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | -19.3    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.365    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.14e+06 |\n",
      "|    total_cost         | 6.67e+03 |\n",
      "|    total_reward       | 6.41e+05 |\n",
      "|    total_reward_pct   | 128      |\n",
      "|    total_trades       | 43642    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 325      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -18.3    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.302    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 328      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -121     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 6.84     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 331       |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | -17.3     |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 0.311     |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 335      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -69.3    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 2.24     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 338       |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | 62.6      |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 2.49      |\n",
      "-------------------------------------\n",
      "======A2C Validation from:  2016-01-04 to  2016-04-05\n",
      "A2C Sharpe Ratio:  0.28845586128525624\n",
      "======A2C Training 2========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c2_126_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.485    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -22.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.408    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.107    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 2.61     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.155    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -29.2     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.02      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.4     |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -37.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.337   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 42.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.867    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.83e+05 |\n",
      "|    total_cost         | 1.7e+05  |\n",
      "|    total_reward       | 1.83e+05 |\n",
      "|    total_reward_pct   | 36.6     |\n",
      "|    total_trades       | 52364    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 2        |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.841    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 14.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.855    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -27.3    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 11.8     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -3.49    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.06e+05 |\n",
      "|    total_cost         | 8.12e+04 |\n",
      "|    total_reward       | 3.06e+05 |\n",
      "|    total_reward_pct   | 61.2     |\n",
      "|    total_trades       | 47515    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -87.2    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 32.4     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.814    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | -0.0216  |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 3.9      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.334    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 151      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 13       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -1.64    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.788    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.13e+06 |\n",
      "|    total_cost         | 5.29e+04 |\n",
      "|    total_reward       | 6.32e+05 |\n",
      "|    total_reward_pct   | 126      |\n",
      "|    total_trades       | 45335    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | -0.122   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 23.7     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | -0.141   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -46.6    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 67.8     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 5.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -65.9    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 10.6     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 4.47     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.92e+06 |\n",
      "|    total_cost         | 8.31e+04 |\n",
      "|    total_reward       | 1.42e+06 |\n",
      "|    total_reward_pct   | 285      |\n",
      "|    total_trades       | 45938    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 3.45     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.0906   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 43.6     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 10.1     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -39.5    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.99     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | -0.00096 |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -617     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 235      |\n",
      "------------------------------------\n",
      "day: 2516, episode: 25\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1979721.32\n",
      "total_reward: 1479721.32\n",
      "total_cost: 26275.16\n",
      "total_trades: 45137\n",
      "Sharpe: 0.738\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.98e+06 |\n",
      "|    total_cost         | 2.63e+04 |\n",
      "|    total_reward       | 1.48e+06 |\n",
      "|    total_reward_pct   | 296      |\n",
      "|    total_trades       | 45137    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 1.73e-06 |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 31.6     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.928    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 91        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | -9.38     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.267     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0.0161   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -55.2    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 5.93     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 98        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | 13.3      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 1.31      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 36.3     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.29e+06 |\n",
      "|    total_cost         | 7.27e+03 |\n",
      "|    total_reward       | 7.94e+05 |\n",
      "|    total_reward_pct   | 159      |\n",
      "|    total_trades       | 40586    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0.000747 |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -116     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 9        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0.512    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 15       |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.23     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 111       |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -9.03     |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.318     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 47       |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.16     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 118       |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | -68.7     |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 2.5       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+06 |\n",
      "|    total_cost         | 7.79e+03 |\n",
      "|    total_reward       | 5.21e+05 |\n",
      "|    total_reward_pct   | 104      |\n",
      "|    total_trades       | 40100    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 53.6     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.77     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 125       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.8     |\n",
      "|    explained_variance | -3.58e-07 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 25.1      |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.721     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0.39     |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 24.7     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.406    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 19.7     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.332    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -11.5    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.293    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.01e+05 |\n",
      "|    total_cost         | 9.02e+03 |\n",
      "|    total_reward       | 4.01e+05 |\n",
      "|    total_reward_pct   | 80.2     |\n",
      "|    total_trades       | 40466    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 4.77e-07 |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -43.3    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.77     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 56       |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 3.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 12.4     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.412    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 149       |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | -33.7     |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.973     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 152       |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | 3.56      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.164     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+06 |\n",
      "|    total_cost         | 7.2e+03  |\n",
      "|    total_reward       | 5.25e+05 |\n",
      "|    total_reward_pct   | 105      |\n",
      "|    total_trades       | 37648    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -4.61    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.195    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | -0.294   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 63.5     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 2.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -49.1    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 1.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 2.34     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 3.8      |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.128    |\n",
      "------------------------------------\n",
      "======A2C 2 Validation from:  2016-01-04 to  2016-04-05\n",
      "A2C Sharpe Ratio:  0.22940175627284287\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_126_7\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 163  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 12   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.13e+05    |\n",
      "|    total_cost           | 4.15e+05    |\n",
      "|    total_reward         | 1.26e+04    |\n",
      "|    total_reward_pct     | 2.52        |\n",
      "|    total_trades         | 69472       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016684504 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0241     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0565      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0444     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.72        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.22e+05    |\n",
      "|    total_cost           | 3.96e+05    |\n",
      "|    total_reward         | -7.85e+04   |\n",
      "|    total_reward_pct     | -15.7       |\n",
      "|    total_trades         | 68759       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016185226 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.0388      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0483     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0485     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.51        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.45e+05    |\n",
      "|    total_cost           | 3.95e+05    |\n",
      "|    total_reward         | -5.46e+04   |\n",
      "|    total_reward_pct     | -10.9       |\n",
      "|    total_trades         | 68682       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020778554 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.105      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0306     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.21        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 3.92e+05  |\n",
      "|    total_cost           | 3.93e+05  |\n",
      "|    total_reward         | -1.08e+05 |\n",
      "|    total_reward_pct     | -21.6     |\n",
      "|    total_trades         | 68415     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 155       |\n",
      "|    iterations           | 5         |\n",
      "|    time_elapsed         | 65        |\n",
      "|    total_timesteps      | 10240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0138267 |\n",
      "|    clip_fraction        | 0.26      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -42.9     |\n",
      "|    explained_variance   | 0.0578    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.102    |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | -0.0451   |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 0.903     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019471588 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.0175     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.145       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.13        |\n",
      "-----------------------------------------\n",
      "day: 2516, episode: 35\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 532472.28\n",
      "total_reward: 32472.28\n",
      "total_cost: 396639.52\n",
      "total_trades: 68588\n",
      "Sharpe: 0.136\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.32e+05    |\n",
      "|    total_cost           | 3.97e+05    |\n",
      "|    total_reward         | 3.25e+04    |\n",
      "|    total_reward_pct     | 6.49        |\n",
      "|    total_trades         | 68588       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022291431 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.17       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.165       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.54        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.98e+05    |\n",
      "|    total_cost           | 3.92e+05    |\n",
      "|    total_reward         | -2.24e+03   |\n",
      "|    total_reward_pct     | -0.448      |\n",
      "|    total_trades         | 68328       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017635321 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.042      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0984      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.43        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.23e+05    |\n",
      "|    total_cost           | 3.78e+05    |\n",
      "|    total_reward         | -7.67e+04   |\n",
      "|    total_reward_pct     | -15.3       |\n",
      "|    total_trades         | 67765       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029082563 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.0983     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0741      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0467     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.32        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 6.14e+05   |\n",
      "|    total_cost           | 3.97e+05   |\n",
      "|    total_reward         | 1.14e+05   |\n",
      "|    total_reward_pct     | 22.8       |\n",
      "|    total_trades         | 68166      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 155        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 131        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03162606 |\n",
      "|    clip_fraction        | 0.341      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | -0.0122    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0762    |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0404    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 1.37       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031108957 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0545      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0782      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.59e+05    |\n",
      "|    total_cost           | 3.9e+05     |\n",
      "|    total_reward         | -4.14e+04   |\n",
      "|    total_reward_pct     | -8.28       |\n",
      "|    total_trades         | 67779       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024665423 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0364      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.257       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.36        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2516, episode: 40\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 546499.29\n",
      "total_reward: 46499.29\n",
      "total_cost: 392692.85\n",
      "total_trades: 68087\n",
      "Sharpe: 0.151\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 5.46e+05  |\n",
      "|    total_cost           | 3.93e+05  |\n",
      "|    total_reward         | 4.65e+04  |\n",
      "|    total_reward_pct     | 9.3       |\n",
      "|    total_trades         | 68087     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 155       |\n",
      "|    iterations           | 13        |\n",
      "|    time_elapsed         | 170       |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0297826 |\n",
      "|    clip_fraction        | 0.261     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.5     |\n",
      "|    explained_variance   | 0.00646   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 0.525     |\n",
      "|    n_updates            | 120       |\n",
      "|    policy_gradient_loss | -0.0348   |\n",
      "|    std                  | 1.03      |\n",
      "|    value_loss           | 1.91      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.36e+05    |\n",
      "|    total_cost           | 3.81e+05    |\n",
      "|    total_reward         | 3.57e+04    |\n",
      "|    total_reward_pct     | 7.15        |\n",
      "|    total_trades         | 67431       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016800988 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0608      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.131       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 1.63        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()# print([self.state[0]])\n",
    "        # print(self.data.close.values.tolist())\n",
    "        # print(list(self.state[(self.stock_dim+1):(self.stock_dim*2+1)]))\n",
    "        # print(sum([self.data[tech].values.tolist() for tech in self.tech_indicator_list ], []) )\n",
    "        # user_features_columns = self.data.columns[-config.NUMBER_OF_USER_FEATURES:]\n",
    "        # print(self.data[user_features_columns].values[0])\n",
    "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs, A2C2_model_kwargs, PPO_model_kwargs, PPO2_model_kwargs, DDPG_model_kwargs, DDPG2_model_kwargs, timesteps_dict)\n",
    "time_elapsed = time.time()-start\n",
    "print(time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "-0qd8acMtj1f",
    "outputId": "a7fa85f0-7825-4b9a-d313-cd99ad70ecb0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter</th>\n",
       "      <th>Val Start</th>\n",
       "      <th>Val End</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>A2C Sharpe</th>\n",
       "      <th>PPO Sharpe</th>\n",
       "      <th>DDPG Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.127394</td>\n",
       "      <td>0.303177</td>\n",
       "      <td>0.264977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.12121</td>\n",
       "      <td>-0.002137</td>\n",
       "      <td>0.070818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.042202</td>\n",
       "      <td>-0.045131</td>\n",
       "      <td>0.151223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.573297</td>\n",
       "      <td>0.566399</td>\n",
       "      <td>0.705078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.122285</td>\n",
       "      <td>-0.138578</td>\n",
       "      <td>-0.031246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>441</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>2017-07-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.150122</td>\n",
       "      <td>0.098266</td>\n",
       "      <td>0.268507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>504</td>\n",
       "      <td>2017-07-05</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.30975</td>\n",
       "      <td>0.240212</td>\n",
       "      <td>0.113961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>567</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.832907</td>\n",
       "      <td>0.487907</td>\n",
       "      <td>0.633911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>630</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.038953</td>\n",
       "      <td>-0.120097</td>\n",
       "      <td>-0.115019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>693</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>2018-07-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.208591</td>\n",
       "      <td>-0.177387</td>\n",
       "      <td>0.055126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>756</td>\n",
       "      <td>2018-07-05</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.466436</td>\n",
       "      <td>0.24904</td>\n",
       "      <td>0.486105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>819</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.302995</td>\n",
       "      <td>-0.419185</td>\n",
       "      <td>-0.196341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>882</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.165556</td>\n",
       "      <td>0.545425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>945</td>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.080163</td>\n",
       "      <td>-0.035117</td>\n",
       "      <td>0.19109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1008</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.042706</td>\n",
       "      <td>-0.256371</td>\n",
       "      <td>-0.160446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1071</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.470853</td>\n",
       "      <td>0.38627</td>\n",
       "      <td>0.561674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1134</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.215682</td>\n",
       "      <td>-0.263877</td>\n",
       "      <td>-0.130965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1197</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.125179</td>\n",
       "      <td>0.074876</td>\n",
       "      <td>0.119182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1260</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.007387</td>\n",
       "      <td>0.041112</td>\n",
       "      <td>0.132897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1323</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.311107</td>\n",
       "      <td>0.176215</td>\n",
       "      <td>0.338129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
       "0    126  2016-01-04  2016-04-05        PPO   0.127394   0.303177    0.264977\n",
       "1    189  2016-04-05  2016-07-05        A2C    0.12121  -0.002137    0.070818\n",
       "2    252  2016-07-05  2016-10-03       DDPG  -0.042202  -0.045131    0.151223\n",
       "3    315  2016-10-03  2017-01-03       DDPG   0.573297   0.566399    0.705078\n",
       "4    378  2017-01-03  2017-04-04       DDPG  -0.122285  -0.138578   -0.031246\n",
       "5    441  2017-04-04  2017-07-05       DDPG   0.150122   0.098266    0.268507\n",
       "6    504  2017-07-05  2017-10-03        A2C    0.30975   0.240212    0.113961\n",
       "7    567  2017-10-03  2018-01-03        A2C   0.832907   0.487907    0.633911\n",
       "8    630  2018-01-03  2018-04-05        A2C  -0.038953  -0.120097   -0.115019\n",
       "9    693  2018-04-05  2018-07-05       DDPG  -0.208591  -0.177387    0.055126\n",
       "10   756  2018-07-05  2018-10-03       DDPG   0.466436    0.24904    0.486105\n",
       "11   819  2018-10-03  2019-01-04       DDPG  -0.302995  -0.419185   -0.196341\n",
       "12   882  2019-01-04  2019-04-05       DDPG   0.435897   0.165556    0.545425\n",
       "13   945  2019-04-05  2019-07-08       DDPG  -0.080163  -0.035117     0.19109\n",
       "14  1008  2019-07-08  2019-10-04        A2C  -0.042706  -0.256371   -0.160446\n",
       "15  1071  2019-10-04  2020-01-06       DDPG   0.470853    0.38627    0.561674\n",
       "16  1134  2020-01-06  2020-04-06       DDPG  -0.215682  -0.263877   -0.130965\n",
       "17  1197  2020-04-06  2020-07-07        A2C   0.125179   0.074876    0.119182\n",
       "18  1260  2020-07-07  2020-10-05       DDPG  -0.007387   0.041112    0.132897\n",
       "19  1323  2020-10-05  2021-01-05       DDPG   0.311107   0.176215    0.338129"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-5475607d3df5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fe' is not defined"
     ]
    }
   ],
   "source": [
    "del fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'finrl.preprocessing.preprocessors.FeatureEngineer'>: it's not the same object as finrl.preprocessing.preprocessors.FeatureEngineer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-a16226672779>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdill\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdill\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'17_year_guardian_sentiment_fixed_fixed_dow.db'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/dill/_dill.py\u001b[0m in \u001b[0;36mdump_session\u001b[0;34m(filename, main, byref, **kwds)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recurse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;31m# disable pickling recursion for globals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# is best indicator of when pickling a session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# If newly opened file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/dill/_dill.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mPicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0mStockPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m         \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# clear record of 'recursion-sensitive' pickled objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/dill/_dill.py\u001b[0m in \u001b[0;36msave_module\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 + [\"__builtins__\", \"__loader__\"]]\n\u001b[1;32m   1326\u001b[0m             pickler.save_reduce(_import_module, (obj.__name__,), obj=obj,\n\u001b[0;32m-> 1327\u001b[0;31m                                 state=_main_dict)\n\u001b[0m\u001b[1;32m   1328\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"# M1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/dill/_dill.py\u001b[0m in \u001b[0;36msave_module_dict\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0;31m# we only care about session the first pass thru\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m         \u001b[0mStockPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"# D2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    883\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/dill/_dill.py\u001b[0m in \u001b[0;36msave_type\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1388\u001b[0m        \u001b[0;31m#print (\"%s\\n%s\" % (obj.__bases__, obj.__dict__))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__qualname__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0mStockPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_global\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"# T4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_global\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m    963\u001b[0m                 raise PicklingError(\n\u001b[1;32m    964\u001b[0m                     \u001b[0;34m\"Can't pickle %r: it's not the same object as %s.%s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                     (obj, module_name, name))\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class 'finrl.preprocessing.preprocessors.FeatureEngineer'>: it's not the same object as finrl.preprocessing.preprocessors.FeatureEngineer"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "dill.dump_session('17_year_guardian_sentiment_fixed_fixed_dow.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('sentiment_1.pkl', 'wb') as f:\n",
    "    pickle.dump(processed_full, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('17_year_guardian_sentiment_fixed_fixed_dow_df_summary.pkl', 'wb') as f:\n",
    "    pickle.dump(df_summary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('17_year_guardian_sentiment_fixed_fixed_dow_processed_full.pkl', 'wb') as f:\n",
    "    pickle.dump(processed_full, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'finrl.env.env_stocktrading.StockTradingEnv'>: it's not the same object as finrl.env.env_stocktrading.StockTradingEnv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-80640691c27e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'17_year_guardian_sentiment_fixed_fixed_dow_ensemble_agent.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensemble_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class 'finrl.env.env_stocktrading.StockTradingEnv'>: it's not the same object as finrl.env.env_stocktrading.StockTradingEnv"
     ]
    }
   ],
   "source": [
    "with open('17_year_guardian_sentiment_fixed_fixed_dow_ensemble_agent.pkl', 'wb') as f:\n",
    "    pickle.dump(ensemble_agent, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "uijiWgkuh1jB",
    "MRiOtrywfAo1",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "include_colab_link": true,
   "name": "FinRL_ensemble_stock_trading_ICAIF_2020.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "more-models",
   "language": "python",
   "name": "more-models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
