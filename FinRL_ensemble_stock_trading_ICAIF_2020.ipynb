{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-LLC/FinRL-Library/blob/master/FinRL_ensemble_stock_trading_ICAIF_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading Using Ensemble Strategy\n",
    "\n",
    "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
    "\n",
    "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
    "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
    "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mPT0ipYE28wL"
   },
   "outputs": [],
   "source": [
    "# ## install finrl library\n",
    "# !pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EeMK7Uentj1V"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lPqeTTwoh1hn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.config import config\n",
    "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "from finrl.model.models import DRLAgent,DRLEnsembleAgent\n",
    "# from finrl.trade.backtest import get_baseline, backtest_stats, backtest_plot\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "87dea23f-469d-4e9d-de91-0f8a74929de2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2004-08-11'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py start_date is a string\n",
    "config.START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "d3baf63f-948a-49f9-f6f2-b7241971b8ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAPL', 'MSFT', 'JPM', 'RTX', 'PG', 'GS', 'NKE', 'DIS', 'AXP', 'HD', 'INTC', 'WMT', 'IBM', 'MRK', 'UNH', 'KO', 'CAT', 'TRV', 'JNJ', 'CVX', 'MCD', 'VZ', 'CSCO', 'XOM', 'BA', 'MMM', 'PFE', 'WBA', 'DD']\n"
     ]
    }
   ],
   "source": [
    "print(config.DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "932583d8-f98b-4243-c02d-375f7272db1a"
   },
   "outputs": [],
   "source": [
    "# from finrl.config.config import MISSING3\n",
    "# df = YahooDownloader(start_date = '2006-01-01',\n",
    "#                      end_date = '2021-06-11',\n",
    "#                      ticker_list = config.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.append(df2).append(df3).append(df4).append(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>2.585000</td>\n",
       "      <td>2.669643</td>\n",
       "      <td>2.580357</td>\n",
       "      <td>2.295634</td>\n",
       "      <td>807234400</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>51.700001</td>\n",
       "      <td>52.580002</td>\n",
       "      <td>51.049999</td>\n",
       "      <td>41.155041</td>\n",
       "      <td>7825700</td>\n",
       "      <td>AXP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>70.400002</td>\n",
       "      <td>70.599998</td>\n",
       "      <td>69.330002</td>\n",
       "      <td>50.119705</td>\n",
       "      <td>4943000</td>\n",
       "      <td>BA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>57.869999</td>\n",
       "      <td>58.110001</td>\n",
       "      <td>57.049999</td>\n",
       "      <td>38.086823</td>\n",
       "      <td>3697500</td>\n",
       "      <td>CAT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>17.209999</td>\n",
       "      <td>17.490000</td>\n",
       "      <td>17.180000</td>\n",
       "      <td>12.956775</td>\n",
       "      <td>55426000</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116020</th>\n",
       "      <td>116020</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>233.100006</td>\n",
       "      <td>234.259995</td>\n",
       "      <td>232.130005</td>\n",
       "      <td>233.949997</td>\n",
       "      <td>4452500</td>\n",
       "      <td>V</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116021</th>\n",
       "      <td>116021</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>57.330002</td>\n",
       "      <td>57.610001</td>\n",
       "      <td>57.220001</td>\n",
       "      <td>57.340000</td>\n",
       "      <td>12013600</td>\n",
       "      <td>VZ</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116022</th>\n",
       "      <td>116022</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>53.799999</td>\n",
       "      <td>55.580002</td>\n",
       "      <td>53.570000</td>\n",
       "      <td>55.310001</td>\n",
       "      <td>6638000</td>\n",
       "      <td>WBA</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116023</th>\n",
       "      <td>116023</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>139.080002</td>\n",
       "      <td>140.190002</td>\n",
       "      <td>139.080002</td>\n",
       "      <td>139.880005</td>\n",
       "      <td>5459500</td>\n",
       "      <td>WMT</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116024</th>\n",
       "      <td>116024</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>63.610001</td>\n",
       "      <td>63.980000</td>\n",
       "      <td>62.250000</td>\n",
       "      <td>62.750000</td>\n",
       "      <td>27488700</td>\n",
       "      <td>XOM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116025 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0        date        open        high         low  \\\n",
       "0                0  2006-01-03    2.585000    2.669643    2.580357   \n",
       "1                1  2006-01-03   51.700001   52.580002   51.049999   \n",
       "2                2  2006-01-03   70.400002   70.599998   69.330002   \n",
       "3                3  2006-01-03   57.869999   58.110001   57.049999   \n",
       "4                4  2006-01-03   17.209999   17.490000   17.180000   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "116020      116020  2021-06-10  233.100006  234.259995  232.130005   \n",
       "116021      116021  2021-06-10   57.330002   57.610001   57.220001   \n",
       "116022      116022  2021-06-10   53.799999   55.580002   53.570000   \n",
       "116023      116023  2021-06-10  139.080002  140.190002  139.080002   \n",
       "116024      116024  2021-06-10   63.610001   63.980000   62.250000   \n",
       "\n",
       "             close     volume   tic  day  \n",
       "0         2.295634  807234400  AAPL    1  \n",
       "1        41.155041    7825700   AXP    1  \n",
       "2        50.119705    4943000    BA    1  \n",
       "3        38.086823    3697500   CAT    1  \n",
       "4        12.956775   55426000  CSCO    1  \n",
       "...            ...        ...   ...  ...  \n",
       "116020  233.949997    4452500     V    3  \n",
       "116021   57.340000   12013600    VZ    3  \n",
       "116022   55.310001    6638000   WBA    3  \n",
       "116023  139.880005    5459500   WMT    3  \n",
       "116024   62.750000   27488700   XOM    3  \n",
       "\n",
       "[116025 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "# df.drop('Unnamed: 0')with open('dji_df_2004-2021.pkl', 'rb') as f:\n",
    "#     df = pickle.load(f)\n",
    "\n",
    "df = pd.read_csv('dji_prices_2020_04_09.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['date', 'tic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "GiRuFOTOtj1Y",
    "outputId": "bf7071db-d71a-4e1b-a28f-8e0145e0d204"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>2.585000</td>\n",
       "      <td>2.669643</td>\n",
       "      <td>2.580357</td>\n",
       "      <td>2.295634</td>\n",
       "      <td>807234400</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>51.700001</td>\n",
       "      <td>52.580002</td>\n",
       "      <td>51.049999</td>\n",
       "      <td>41.155041</td>\n",
       "      <td>7825700</td>\n",
       "      <td>AXP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>70.400002</td>\n",
       "      <td>70.599998</td>\n",
       "      <td>69.330002</td>\n",
       "      <td>50.119705</td>\n",
       "      <td>4943000</td>\n",
       "      <td>BA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>57.869999</td>\n",
       "      <td>58.110001</td>\n",
       "      <td>57.049999</td>\n",
       "      <td>38.086823</td>\n",
       "      <td>3697500</td>\n",
       "      <td>CAT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>17.209999</td>\n",
       "      <td>17.490000</td>\n",
       "      <td>17.180000</td>\n",
       "      <td>12.956775</td>\n",
       "      <td>55426000</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       open       high        low      close     volume   tic  \\\n",
       "0  2006-01-03   2.585000   2.669643   2.580357   2.295634  807234400  AAPL   \n",
       "1  2006-01-03  51.700001  52.580002  51.049999  41.155041    7825700   AXP   \n",
       "2  2006-01-03  70.400002  70.599998  69.330002  50.119705    4943000    BA   \n",
       "3  2006-01-03  57.869999  58.110001  57.049999  38.086823    3697500   CAT   \n",
       "4  2006-01-03  17.209999  17.490000  17.180000  12.956775   55426000  CSCO   \n",
       "\n",
       "   day  \n",
       "0    1  \n",
       "1    1  \n",
       "2    1  \n",
       "3    1  \n",
       "4    1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DSw4ZEzVtj1Z",
    "outputId": "1a04171b-04c8-4974-9c63-3195261d8fd5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116020</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>233.100006</td>\n",
       "      <td>234.259995</td>\n",
       "      <td>232.130005</td>\n",
       "      <td>233.949997</td>\n",
       "      <td>4452500</td>\n",
       "      <td>V</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116021</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>57.330002</td>\n",
       "      <td>57.610001</td>\n",
       "      <td>57.220001</td>\n",
       "      <td>57.340000</td>\n",
       "      <td>12013600</td>\n",
       "      <td>VZ</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116022</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>53.799999</td>\n",
       "      <td>55.580002</td>\n",
       "      <td>53.570000</td>\n",
       "      <td>55.310001</td>\n",
       "      <td>6638000</td>\n",
       "      <td>WBA</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116023</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>139.080002</td>\n",
       "      <td>140.190002</td>\n",
       "      <td>139.080002</td>\n",
       "      <td>139.880005</td>\n",
       "      <td>5459500</td>\n",
       "      <td>WMT</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116024</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>63.610001</td>\n",
       "      <td>63.980000</td>\n",
       "      <td>62.250000</td>\n",
       "      <td>62.750000</td>\n",
       "      <td>27488700</td>\n",
       "      <td>XOM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date        open        high         low       close    volume  \\\n",
       "116020  2021-06-10  233.100006  234.259995  232.130005  233.949997   4452500   \n",
       "116021  2021-06-10   57.330002   57.610001   57.220001   57.340000  12013600   \n",
       "116022  2021-06-10   53.799999   55.580002   53.570000   55.310001   6638000   \n",
       "116023  2021-06-10  139.080002  140.190002  139.080002  139.880005   5459500   \n",
       "116024  2021-06-10   63.610001   63.980000   62.250000   62.750000  27488700   \n",
       "\n",
       "        tic  day  \n",
       "116020    V    3  \n",
       "116021   VZ    3  \n",
       "116022  WBA    3  \n",
       "116023  WMT    3  \n",
       "116024  XOM    3  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "b7b78172-8c8a-41c9-c8a6-0167edb9bd11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116025, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAPL', 'AXP', 'BA', 'CAT', 'CSCO', 'CVX', 'DD', 'DIS', 'GS', 'HD',\n",
       "       'IBM', 'INTC', 'JNJ', 'JPM', 'KO', 'MCD', 'MMM', 'MRK', 'MSFT',\n",
       "       'NKE', 'PFE', 'PG', 'RTX', 'TRV', 'UNH', 'VZ', 'WBA', 'WMT', 'XOM',\n",
       "       'V'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tic.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('dji_df_2004-2021.pkl', 'wb') as f:\n",
    "#     pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/roman/Work/trading-bot/notebooks/2004-2021_imputed_sentiment_final_df.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7093a9a65924>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/roman/Work/trading-bot/notebooks/2004-2021_imputed_sentiment_final_df.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdaily_sentiment_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/roman/Work/trading-bot/notebooks/2004-2021_imputed_sentiment_final_df.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('/home/roman/Work/trading-bot/notebooks/2004-2021_imputed_sentiment_final_df.pkl', 'rb') as f:\n",
    "    daily_sentiment_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'doc2vec_2004_2021_expanded_world_df.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b7847b9ba1bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'doc2vec_2004_2021_expanded_world_df.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdoc2vec_2004_2021_expanded_world_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'doc2vec_2004_2021_expanded_world_df.pkl'"
     ]
    }
   ],
   "source": [
    "with open('doc2vec_2004_2021_expanded_world_df.pkl', 'rb') as f:\n",
    "    doc2vec_2004_2021_expanded_world_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'daily_sentiment_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-46692267fd80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdaily_sentiment_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'daily_sentiment_df' is not defined"
     ]
    }
   ],
   "source": [
    "daily_sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "jgXfBcjxtj1a",
    "outputId": "abf8d5bb-2cd2-4c12-d4cb-ed1c429e60ce",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = config.TECHNICAL_INDICATORS_LIST,\n",
    "                    use_turbulence=True)\n",
    "\n",
    "processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'open',\n",
       " 'high',\n",
       " 'low',\n",
       " 'close',\n",
       " 'volume',\n",
       " 'tic',\n",
       " 'day',\n",
       " 'macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma',\n",
       " 'turbulence']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(processed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "R_3v-ycktj1b"
   },
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "grvhGJJII3Xn",
    "outputId": "91d09c37-b0e9-4c5c-d532-967e40d11f41"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101723</th>\n",
       "      <td>2015-04-16</td>\n",
       "      <td>TRV</td>\n",
       "      <td>107.779999</td>\n",
       "      <td>109.010002</td>\n",
       "      <td>107.459999</td>\n",
       "      <td>93.760399</td>\n",
       "      <td>1804300.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.150807</td>\n",
       "      <td>94.854946</td>\n",
       "      <td>91.686619</td>\n",
       "      <td>54.404673</td>\n",
       "      <td>44.835992</td>\n",
       "      <td>10.741828</td>\n",
       "      <td>93.003172</td>\n",
       "      <td>92.340575</td>\n",
       "      <td>39.115192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86973</th>\n",
       "      <td>2013-12-11</td>\n",
       "      <td>CAT</td>\n",
       "      <td>86.029999</td>\n",
       "      <td>86.220001</td>\n",
       "      <td>85.120003</td>\n",
       "      <td>68.249901</td>\n",
       "      <td>5624100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.306393</td>\n",
       "      <td>69.107187</td>\n",
       "      <td>65.736793</td>\n",
       "      <td>52.773616</td>\n",
       "      <td>155.943945</td>\n",
       "      <td>12.718046</td>\n",
       "      <td>67.316217</td>\n",
       "      <td>67.537157</td>\n",
       "      <td>67.961726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144988</th>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>XOM</td>\n",
       "      <td>80.029999</td>\n",
       "      <td>80.790001</td>\n",
       "      <td>80.019997</td>\n",
       "      <td>69.920242</td>\n",
       "      <td>7412300.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.850219</td>\n",
       "      <td>70.748913</td>\n",
       "      <td>68.462019</td>\n",
       "      <td>57.885933</td>\n",
       "      <td>57.874436</td>\n",
       "      <td>15.426671</td>\n",
       "      <td>68.995663</td>\n",
       "      <td>65.662824</td>\n",
       "      <td>15.634157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83409</th>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>HD</td>\n",
       "      <td>79.150002</td>\n",
       "      <td>79.230003</td>\n",
       "      <td>77.180000</td>\n",
       "      <td>64.728661</td>\n",
       "      <td>8648100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.081357</td>\n",
       "      <td>67.580016</td>\n",
       "      <td>65.061893</td>\n",
       "      <td>49.122593</td>\n",
       "      <td>-151.164985</td>\n",
       "      <td>16.121825</td>\n",
       "      <td>66.386430</td>\n",
       "      <td>65.374413</td>\n",
       "      <td>37.659185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28040</th>\n",
       "      <td>2008-07-25</td>\n",
       "      <td>PFE</td>\n",
       "      <td>17.922201</td>\n",
       "      <td>17.979128</td>\n",
       "      <td>17.760912</td>\n",
       "      <td>10.709130</td>\n",
       "      <td>45163057.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.088633</td>\n",
       "      <td>10.797240</td>\n",
       "      <td>9.652154</td>\n",
       "      <td>51.770312</td>\n",
       "      <td>189.389123</td>\n",
       "      <td>25.038815</td>\n",
       "      <td>10.151281</td>\n",
       "      <td>10.577465</td>\n",
       "      <td>29.911505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  tic        open        high         low      close  \\\n",
       "101723  2015-04-16  TRV  107.779999  109.010002  107.459999  93.760399   \n",
       "86973   2013-12-11  CAT   86.029999   86.220001   85.120003  68.249901   \n",
       "144988  2019-03-28  XOM   80.029999   80.790001   80.019997  69.920242   \n",
       "83409   2013-08-14   HD   79.150002   79.230003   77.180000  64.728661   \n",
       "28040   2008-07-25  PFE   17.922201   17.979128   17.760912  10.709130   \n",
       "\n",
       "            volume  day      macd    boll_ub    boll_lb     rsi_30  \\\n",
       "101723   1804300.0  3.0  0.150807  94.854946  91.686619  54.404673   \n",
       "86973    5624100.0  2.0  0.306393  69.107187  65.736793  52.773616   \n",
       "144988   7412300.0  3.0  0.850219  70.748913  68.462019  57.885933   \n",
       "83409    8648100.0  2.0  0.081357  67.580016  65.061893  49.122593   \n",
       "28040   45163057.0  4.0  0.088633  10.797240   9.652154  51.770312   \n",
       "\n",
       "            cci_30      dx_30  close_30_sma  close_60_sma  turbulence  \n",
       "101723   44.835992  10.741828     93.003172     92.340575   39.115192  \n",
       "86973   155.943945  12.718046     67.316217     67.537157   67.961726  \n",
       "144988   57.874436  15.426671     68.995663     65.662824   15.634157  \n",
       "83409  -151.164985  16.121825     66.386430     65.374413   37.659185  \n",
       "28040   189.389123  25.038815     10.151281     10.577465   29.911505  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2006-01-03'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full['date'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "187c6d1b-3e91-40f8-dafd-230d787f2ee1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.TECHNICAL_INDICATORS_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "8a2c943b-1be4-4b8d-b64f-666e0852b7e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 30, User Features: 0, State Space: 301\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(processed_full.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.TECHNICAL_INDICATORS_LIST)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, User Features: {config.NUMBER_OF_USER_FEATURES}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 50_000_000/100, #Since in Indonesia the minimum number of shares per trx is 100, then we scaled the initial amount by dividing it with 100 \n",
    "    \"buy_cost_pct\": 0.001, #IPOT has 0.19% buy cost\n",
    "    \"sell_cost_pct\": 0.001, #IPOT has 0.29% sell cost\n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"print_verbosity\":5\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms.\n",
    "\n",
    "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "v-gthCxMtj1d"
   },
   "outputs": [],
   "source": [
    "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
    "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
    "train_start = '2006-01-03'\n",
    "train_end = '2016-01-01'\n",
    "val_test_start = '2016-01-01'\n",
    "val_test_end = '2021-06-11'\n",
    "\n",
    "ensemble_agent = DRLEnsembleAgent(df=processed_full,\n",
    "                 train_period=(train_start,train_end),\n",
    "                 val_test_period=(val_test_start,val_test_end),\n",
    "                 rebalance_window=rebalance_window, \n",
    "                 validation_window=validation_window,\n",
    "                 **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print([0]*0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "KsfEHa_Etj1d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A2C_model_kwargs = {\n",
    "                    'n_steps': 5,\n",
    "                    'ent_coef': 0.01,\n",
    "                    'learning_rate': 0.0002\n",
    "                    }\n",
    "\n",
    "PPO_model_kwargs = {\n",
    "                    \"ent_coef\":0.01,\n",
    "                    \"n_steps\": 2048,\n",
    "                    \"learning_rate\": 0.0001,\n",
    "                    \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "DDPG_model_kwargs = {\n",
    "                      \"action_noise\":\"ornstein_uhlenbeck\",\n",
    "                      \"buffer_size\": 50_000,\n",
    "                      \"learning_rate\": 0.000002,\n",
    "                      \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "timesteps_dict = {'a2c' : 20_000, \n",
    "                 'ppo' : 20_000, \n",
    "                 'ddpg' : 10_000,\n",
    "                  'a2c2' : 25_000, \n",
    "                 'ppo2' : 25_000, \n",
    "                 'ddpg2' : 12_000\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1lyCECstj1e",
    "outputId": "72ac1ecc-909e-4d4c-d724-d906d7881ed9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Start Ensemble Strategy============\n",
      "============================================\n",
      "39.25064963834648\n",
      "turbulence_threshold:  458.40565412601285\n",
      "======Model training from:  2006-01-03 to  2016-01-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0002}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_126_6\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -1.39    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -3.93    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 90       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.272   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 20.9     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.717    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 90       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.0552  |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -19.9    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.408    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0511  |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -36.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.966    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0839   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 28.7     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.528    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.62e+05 |\n",
      "|    total_cost         | 1.57e+05 |\n",
      "|    total_reward       | 1.71e+11 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 67240    |\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.273    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 17.9     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.409    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.539   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -4.01    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.308    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.557   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 7.24     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.315    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 24       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.427    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0556  |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 19.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.428    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.12e+06 |\n",
      "|    total_cost         | 1.5e+05  |\n",
      "|    total_reward       | 3.7e+11  |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 66426    |\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.447   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -45      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.32    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 6.43     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.317    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.162   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 13.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.389    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.15     |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 50.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.35     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0962  |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 85.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.7      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.88e+05 |\n",
      "|    total_cost         | 1.4e+05  |\n",
      "|    total_reward       | 1.06e+11 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 64762    |\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.509   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 47.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.595    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -37.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.284   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 28       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.212   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -34.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.736    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.123   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -9.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.693    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.56e+05 |\n",
      "|    total_cost         | 1.2e+05  |\n",
      "|    total_reward       | 3.83e+10 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 61272    |\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.134   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 12.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.392    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.115   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 35       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.733    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.273   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 17.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.665    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.145    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -25.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.704    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.188    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -199     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 23.6     |\n",
      "------------------------------------\n",
      "day: 2516, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 704718.38\n",
      "total_reward: 22359059604.40\n",
      "total_cost: 138950.11\n",
      "total_trades: 64245\n",
      "Sharpe: 0.267\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.05e+05 |\n",
      "|    total_cost         | 1.39e+05 |\n",
      "|    total_reward       | 2.24e+10 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 64245    |\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.297    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 21       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.486    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.97e-06 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 5.31     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0756   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.174    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 6.3      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.54     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.137   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 26.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.528    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.235    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 22.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.11e+06 |\n",
      "|    total_cost         | 1.05e+05 |\n",
      "|    total_reward       | 3.44e+11 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 59232    |\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0548   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -74      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.484    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 12.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.117    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.574   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 5.07     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.209    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0237   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 33.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.919    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.00298 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -88.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+06 |\n",
      "|    total_cost         | 9.06e+04 |\n",
      "|    total_reward       | 2.32e+11 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 57257    |\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.354   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 31.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.502    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0127   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 9.01     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.118    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.323   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 35.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.971    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0428   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 52.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 216      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 13.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.638    |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2016-01-04 to  2016-04-05\n",
      "A2C Sharpe Ratio:  0.30655781595399456\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_126_4\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 99   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 20   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 8.72e+05     |\n",
      "|    total_cost           | 1.84e+05     |\n",
      "|    total_reward         | 1.07e+11     |\n",
      "|    total_reward_pct     | -100         |\n",
      "|    total_trades         | 70645        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 98           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069312565 |\n",
      "|    clip_fraction        | 0.0925       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | -0.0479      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.662        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0312      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 2.33         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2516, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 821820.41\n",
      "total_reward: 72949916354.36\n",
      "total_cost: 177774.94\n",
      "total_trades: 70056\n",
      "Sharpe: 0.352\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 8.22e+05     |\n",
      "|    total_cost           | 1.78e+05     |\n",
      "|    total_reward         | 7.29e+10     |\n",
      "|    total_reward_pct     | -100         |\n",
      "|    total_trades         | 70056        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 97           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023838077 |\n",
      "|    clip_fraction        | 0.0788       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | -0.0354      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.644        |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0252      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 2.56         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.61e+05    |\n",
      "|    total_cost           | 1.71e+05    |\n",
      "|    total_reward         | 1.24e+10    |\n",
      "|    total_reward_pct     | -100        |\n",
      "|    total_trades         | 69042       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005886996 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0236     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.54        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.41        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.72e+05    |\n",
      "|    total_cost           | 1.79e+05    |\n",
      "|    total_reward         | 1.05e+11    |\n",
      "|    total_reward_pct     | -100        |\n",
      "|    total_trades         | 69997       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012309352 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0776     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.182       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0341     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.48        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010770658 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.0219      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.594       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.63        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 7.2e+05      |\n",
      "|    total_cost           | 1.75e+05     |\n",
      "|    total_reward         | 2.7e+10      |\n",
      "|    total_reward_pct     | -100         |\n",
      "|    total_trades         | 69419        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 97           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 146          |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074418793 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.7        |\n",
      "|    explained_variance   | -0.0137      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.452        |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0344      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 1.85         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.19e+05   |\n",
      "|    total_cost           | 1.75e+05   |\n",
      "|    total_reward         | 1.48e+11   |\n",
      "|    total_reward_pct     | -100       |\n",
      "|    total_trades         | 69578      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 97         |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 167        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01026799 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | 0.0205     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.751      |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0302    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 2.9        |\n",
      "----------------------------------------\n",
      "day: 2516, episode: 15\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 750303.08\n",
      "total_reward: 39098545497.15\n",
      "total_cost: 172510.09\n",
      "total_trades: 69370\n",
      "Sharpe: 0.312\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.5e+05     |\n",
      "|    total_cost           | 1.73e+05    |\n",
      "|    total_reward         | 3.91e+10    |\n",
      "|    total_reward_pct     | -100        |\n",
      "|    total_trades         | 69370       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013288191 |\n",
      "|    clip_fraction        | 0.0877      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0232     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.615       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.52        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.39e+05    |\n",
      "|    total_cost           | 1.75e+05    |\n",
      "|    total_reward         | 8.46e+10    |\n",
      "|    total_reward_pct     | -100        |\n",
      "|    total_trades         | 69121       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009245239 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.099      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.519       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.44        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2016-01-04 to  2016-04-05\n",
      "PPO Sharpe Ratio:  0.3046948955607063\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 2e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_126_3\n",
      "day: 2516, episode: 20\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 961172.97\n",
      "total_reward: 179409130686.44\n",
      "total_cost: 916.34\n",
      "total_trades: 39195\n",
      "Sharpe: 0.422\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 9.43e+05 |\n",
      "|    total_cost       | 790      |\n",
      "|    total_reward     | 1.63e+11 |\n",
      "|    total_reward_pct | -100     |\n",
      "|    total_trades     | 43836    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 54       |\n",
      "|    time_elapsed     | 183      |\n",
      "|    total timesteps  | 10068    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -2.04    |\n",
      "|    critic_loss      | 3.99     |\n",
      "|    learning_rate    | 2e-06    |\n",
      "|    n_updates        | 7551     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2016-01-04 to  2016-04-05\n",
      "======Best Model Retraining from:  2006-01-03 to  2016-04-05\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0002}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/ensemble_126_2\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 90       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.354   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -17.9    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.438    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.777   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 6.64     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.357    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.316   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -25.9    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.435    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -1.16    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -0.29    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.196    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.946   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 11.6     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.113    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.49e+05 |\n",
      "|    total_cost         | 1.67e+05 |\n",
      "|    total_reward       | 1.79e+11 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 70221    |\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.139    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -58.8    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.143    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 62.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.134    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 34.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -1.28    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -21.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.362    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.274    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -78      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.45e+05 |\n",
      "|    total_cost         | 1.59e+05 |\n",
      "|    total_reward       | 3.53e+10 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 68652    |\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0359  |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 20       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.365    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -1.31    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 58.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.92     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.577   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 45       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.572    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 10.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.00611 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 20.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.898    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.65e+05 |\n",
      "|    total_cost         | 1.59e+05 |\n",
      "|    total_reward       | 1.82e+11 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 68773    |\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -2.54    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -14.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.129    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.119    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 54.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.295    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 37.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.832    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.18    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -10.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.387    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.1     |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 30.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.22e+06 |\n",
      "|    total_cost         | 1.54e+05 |\n",
      "|    total_reward       | 5.42e+11 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 67977    |\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.341   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 43.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.192    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -33.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.2     |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 41.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.747    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 18.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.205    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.0199  |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 20.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.391    |\n",
      "------------------------------------\n",
      "day: 2579, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1146570.93\n",
      "total_reward: 403251381243.19\n",
      "total_cost: 135087.21\n",
      "total_trades: 65072\n",
      "Sharpe: 0.482\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.15e+06 |\n",
      "|    total_cost         | 1.35e+05 |\n",
      "|    total_reward       | 4.03e+11 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 65072    |\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.225    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -7.61    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.158    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0276   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 19.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.232    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.0441  |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 10.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.488    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.3     |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -29.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.484    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0241   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 14.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.179    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.31e+05 |\n",
      "|    total_cost         | 1.11e+05 |\n",
      "|    total_reward       | 7.53e+10 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 61915    |\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -9.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0992   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.53    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -94.4    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -7.53    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 20.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.388    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.0503  |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 1.73     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.105   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -23.4    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.467    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.000823 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -16      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.332    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.84e+05 |\n",
      "|    total_cost         | 1.14e+05 |\n",
      "|    total_reward       | 1.7e+10  |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 60743    |\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.27     |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 28.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.497    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 16.3     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.184    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0343  |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -17.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0402  |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 54.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.56     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Trading from:  2016-04-05 to  2016-07-05\n",
      "============================================\n",
      "44.00922414009339\n",
      "turbulence_threshold:  458.40565412601285\n",
      "======Model training from:  2006-01-03 to  2016-04-05\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0002}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_189_3\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 90       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.303    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -21.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.437    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 90        |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | 14.5      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.44      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.793   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -40.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -2.31    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -29      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.597    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 17.7     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.173    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.1e+05  |\n",
      "|    total_cost         | 1.78e+05 |\n",
      "|    total_reward       | 6.47e+10 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 70548    |\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.757   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -36.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.142   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 50       |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.00503  |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 21.3     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.159   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -7.96    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.167    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -1.19    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 8.48     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.283    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.99e+05 |\n",
      "|    total_cost         | 1.55e+05 |\n",
      "|    total_reward       | 5.58e+10 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 68054    |\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.619   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 31       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.828    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.207    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 62.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.293   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 37.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.779    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 20.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.406    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.726   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 7.45     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0969   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7e+05    |\n",
      "|    total_cost         | 1.55e+05 |\n",
      "|    total_reward       | 2.05e+10 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 67918    |\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -1.86    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -3.31    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.145    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -2.64    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 87       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -3.6     |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -8.14    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.209    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -1.03    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -1.81    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.657    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0454   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -17.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.98e+05 |\n",
      "|    total_cost         | 1.44e+05 |\n",
      "|    total_reward       | 1.11e+11 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 64873    |\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0739   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 33.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.749    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.228    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -36.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.401   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 26.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.601    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.502   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 10.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.315    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 46.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.86     |\n",
      "------------------------------------\n",
      "day: 2579, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1037709.09\n",
      "total_reward: 223426365268.65\n",
      "total_cost: 129059.44\n",
      "total_trades: 62291\n",
      "Sharpe: 0.386\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+06 |\n",
      "|    total_cost         | 1.29e+05 |\n",
      "|    total_reward       | 2.23e+11 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 62291    |\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.466    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -35.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.897    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -4.58    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 5        |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.143    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.134   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -15      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.14     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -2.16    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -13.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.166    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -7.28    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -7.24    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.301    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.6e+05  |\n",
      "|    total_cost         | 1.26e+05 |\n",
      "|    total_reward       | 1.21e+09 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 62416    |\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -8.25    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0742   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.401    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -72.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.112    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 32.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.575    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.0986   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 8.87     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.229    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.0752  |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -31.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.552    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.34    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 10.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.319    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.59e+05 |\n",
      "|    total_cost         | 1.31e+05 |\n",
      "|    total_reward       | 9.12e+10 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 63815    |\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.742   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 15.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.216    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.822    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 1.31     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0301   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.014    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 11.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.363    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.903   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 64.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.51     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2016-04-05 to  2016-07-05\n",
      "A2C Sharpe Ratio:  0.015496767138027643\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_189_3\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 98   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 20   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 7.24e+05     |\n",
      "|    total_cost           | 1.83e+05     |\n",
      "|    total_reward         | 2.81e+10     |\n",
      "|    total_reward_pct     | -100         |\n",
      "|    total_trades         | 71503        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 97           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018326435 |\n",
      "|    clip_fraction        | 0.0991       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | -0.124       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.423        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0275      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 2.38         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2579, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 700509.35\n",
      "total_reward: 21255365214.45\n",
      "total_cost: 181576.56\n",
      "total_trades: 71473\n",
      "Sharpe: 0.264\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.01e+05    |\n",
      "|    total_cost           | 1.82e+05    |\n",
      "|    total_reward         | 2.13e+10    |\n",
      "|    total_reward_pct     | -100        |\n",
      "|    total_trades         | 71473       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005183425 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0876     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.879       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.59e+05    |\n",
      "|    total_cost           | 1.83e+05    |\n",
      "|    total_reward         | 3.97e+10    |\n",
      "|    total_reward_pct     | -100        |\n",
      "|    total_trades         | 71389       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013299603 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.0242      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.644       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.03        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011743242 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0425     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.386       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.77        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.27e+05    |\n",
      "|    total_cost           | 1.85e+05    |\n",
      "|    total_reward         | 7.5e+10     |\n",
      "|    total_reward_pct     | -100        |\n",
      "|    total_trades         | 71449       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012312079 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0775     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.745       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.4         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.43e+05    |\n",
      "|    total_cost           | 1.72e+05    |\n",
      "|    total_reward         | 3.32e+10    |\n",
      "|    total_reward_pct     | -100        |\n",
      "|    total_trades         | 70035       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008179724 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0132     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.773       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.26        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.13e+06     |\n",
      "|    total_cost           | 1.88e+05     |\n",
      "|    total_reward         | 4.08e+11     |\n",
      "|    total_reward_pct     | -100         |\n",
      "|    total_trades         | 72276        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 95           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085005555 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.7        |\n",
      "|    explained_variance   | -0.0667      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.779        |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0313      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 2.65         |\n",
      "------------------------------------------\n",
      "day: 2579, episode: 15\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 835252.90\n",
      "total_reward: 76812899937.84\n",
      "total_cost: 181049.52\n",
      "total_trades: 71258\n",
      "Sharpe: 0.342\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.35e+05    |\n",
      "|    total_cost           | 1.81e+05    |\n",
      "|    total_reward         | 7.68e+10    |\n",
      "|    total_reward_pct     | -100        |\n",
      "|    total_trades         | 71258       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007775978 |\n",
      "|    clip_fraction        | 0.0664      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.023      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.932       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.77        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 95           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 214          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0153078865 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.7        |\n",
      "|    explained_variance   | -0.0286      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.559        |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0263      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.7          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2016-04-05 to  2016-07-05\n",
      "PPO Sharpe Ratio:  -0.02673465322518997\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 2e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_189_3\n",
      "day: 2579, episode: 20\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1124479.01\n",
      "total_reward: 375766265132.23\n",
      "total_cost: 980.41\n",
      "total_trades: 30013\n",
      "Sharpe: 0.482\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.12e+06 |\n",
      "|    total_cost       | 980      |\n",
      "|    total_reward     | 3.76e+11 |\n",
      "|    total_reward_pct | -100     |\n",
      "|    total_trades     | 30013    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 55       |\n",
      "|    time_elapsed     | 185      |\n",
      "|    total timesteps  | 10320    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -33.1    |\n",
      "|    critic_loss      | 3.26     |\n",
      "|    learning_rate    | 2e-06    |\n",
      "|    n_updates        | 7740     |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2016-04-05 to  2016-07-05\n",
      "======Best Model Retraining from:  2006-01-03 to  2016-07-05\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 2e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_189_2\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.18e+06 |\n",
      "|    total_cost       | 1.12e+03 |\n",
      "|    total_reward     | 4.64e+11 |\n",
      "|    total_reward_pct | -100     |\n",
      "|    total_trades     | 36989    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 54       |\n",
      "|    time_elapsed     | 195      |\n",
      "|    total timesteps  | 10572    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -15      |\n",
      "|    critic_loss      | 2.02     |\n",
      "|    learning_rate    | 2e-06    |\n",
      "|    n_updates        | 7929     |\n",
      "----------------------------------\n",
      "======Trading from:  2016-07-05 to  2016-10-03\n",
      "============================================\n",
      "12.081121283288908\n",
      "turbulence_threshold:  458.40565412601285\n",
      "======Model training from:  2006-01-03 to  2016-07-05\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0002}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_252_3\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.637   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -13.1    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.527    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.354   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 16.9     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.235    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.977   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -20.9    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.498    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -3.29    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -58.8    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.231    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -22.5    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.604    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.98e+05 |\n",
      "|    total_cost         | 1.77e+05 |\n",
      "|    total_reward       | 5.88e+10 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 72462    |\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.4     |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 17.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.344    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.105    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -30.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.746    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.808   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -35      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.943    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.319   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 47.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.129    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 30.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.892    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.59e+05 |\n",
      "|    total_cost         | 1.63e+05 |\n",
      "|    total_reward       | 9.07e+10 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 69992    |\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -2.74    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -14      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.234    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.328    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -103     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.491    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 43.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.64    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 7.75     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.235    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0921   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -125     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 9.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.24e+05 |\n",
      "|    total_cost         | 1.6e+05  |\n",
      "|    total_reward       | 1.45e+11 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 69164    |\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.167    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -0.833   |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0312   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.238   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 16.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.698    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -1.49    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -6.77    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0543   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.227    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -31.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.579    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.259   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 25.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.779    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.259    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 34.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.918    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+06 |\n",
      "|    total_cost         | 1.49e+05 |\n",
      "|    total_reward       | 2.91e+11 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 67342    |\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -1.67    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -12.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.0456  |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -50.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.237   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 71.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.21     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -2.57    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -0.422   |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0869   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.00631  |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -24.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.467    |\n",
      "------------------------------------\n",
      "day: 2642, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1091617.26\n",
      "total_reward: 336535958120.71\n",
      "total_cost: 140713.67\n",
      "total_trades: 66364\n",
      "Sharpe: 0.481\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.09e+06 |\n",
      "|    total_cost         | 1.41e+05 |\n",
      "|    total_reward       | 3.37e+11 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 66364    |\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.438    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 9.32     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0813   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.105    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 10.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.123    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.454    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 3.92     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0676   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.0314   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 3.59     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0589   |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()# print([self.state[0]])\n",
    "        # print(self.data.close.values.tolist())\n",
    "        # print(list(self.state[(self.stock_dim+1):(self.stock_dim*2+1)]))\n",
    "        # print(sum([self.data[tech].values.tolist() for tech in self.tech_indicator_list ], []) )\n",
    "        # user_features_columns = self.data.columns[-config.NUMBER_OF_USER_FEATURES:]\n",
    "        # print(self.data[user_features_columns].values[0])\n",
    "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs, PPO_model_kwargs, DDPG_model_kwargs, timesteps_dict)\n",
    "time_elapsed = time.time()-start\n",
    "print(time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "-0qd8acMtj1f",
    "outputId": "a7fa85f0-7825-4b9a-d313-cd99ad70ecb0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter</th>\n",
       "      <th>Val Start</th>\n",
       "      <th>Val End</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>A2C Sharpe</th>\n",
       "      <th>PPO Sharpe</th>\n",
       "      <th>DDPG Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.2314</td>\n",
       "      <td>0.137868</td>\n",
       "      <td>0.138116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.023251</td>\n",
       "      <td>-0.02747</td>\n",
       "      <td>0.027674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.110485</td>\n",
       "      <td>-0.199811</td>\n",
       "      <td>0.160881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.314206</td>\n",
       "      <td>0.153133</td>\n",
       "      <td>0.621001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.203685</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>0.21147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>441</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>2017-07-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.095114</td>\n",
       "      <td>0.033792</td>\n",
       "      <td>0.317426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>504</td>\n",
       "      <td>2017-07-05</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.377324</td>\n",
       "      <td>0.121963</td>\n",
       "      <td>0.251148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>567</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.574725</td>\n",
       "      <td>0.341799</td>\n",
       "      <td>0.793806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>630</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>-0.112015</td>\n",
       "      <td>-0.014637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>693</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>2018-07-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.02719</td>\n",
       "      <td>-0.1257</td>\n",
       "      <td>-0.015095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>756</td>\n",
       "      <td>2018-07-05</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.450082</td>\n",
       "      <td>0.147365</td>\n",
       "      <td>0.418461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>819</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.25981</td>\n",
       "      <td>-0.40007</td>\n",
       "      <td>-0.330967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>882</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.406631</td>\n",
       "      <td>0.190899</td>\n",
       "      <td>0.495319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>945</td>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.032597</td>\n",
       "      <td>0.109825</td>\n",
       "      <td>0.240779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1008</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.104909</td>\n",
       "      <td>-0.200958</td>\n",
       "      <td>-0.12477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1071</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.212395</td>\n",
       "      <td>-0.099511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1134</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.372937</td>\n",
       "      <td>-0.347581</td>\n",
       "      <td>-0.26482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1197</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.17941</td>\n",
       "      <td>0.079824</td>\n",
       "      <td>0.274104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1260</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.017552</td>\n",
       "      <td>-0.013615</td>\n",
       "      <td>0.035169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1323</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.330596</td>\n",
       "      <td>0.262684</td>\n",
       "      <td>0.055981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
       "0    126  2016-01-04  2016-04-05        A2C     0.2314   0.137868    0.138116\n",
       "1    189  2016-04-05  2016-07-05       DDPG   0.023251   -0.02747    0.027674\n",
       "2    252  2016-07-05  2016-10-03       DDPG   0.110485  -0.199811    0.160881\n",
       "3    315  2016-10-03  2017-01-03       DDPG   0.314206   0.153133    0.621001\n",
       "4    378  2017-01-03  2017-04-04       DDPG   0.203685   0.021583     0.21147\n",
       "5    441  2017-04-04  2017-07-05       DDPG   0.095114   0.033792    0.317426\n",
       "6    504  2017-07-05  2017-10-03        A2C   0.377324   0.121963    0.251148\n",
       "7    567  2017-10-03  2018-01-03       DDPG   0.574725   0.341799    0.793806\n",
       "8    630  2018-01-03  2018-04-05        A2C   0.001569  -0.112015   -0.014637\n",
       "9    693  2018-04-05  2018-07-05       DDPG   -0.02719    -0.1257   -0.015095\n",
       "10   756  2018-07-05  2018-10-03        A2C   0.450082   0.147365    0.418461\n",
       "11   819  2018-10-03  2019-01-04        A2C   -0.25981   -0.40007   -0.330967\n",
       "12   882  2019-01-04  2019-04-05       DDPG   0.406631   0.190899    0.495319\n",
       "13   945  2019-04-05  2019-07-08       DDPG  -0.032597   0.109825    0.240779\n",
       "14  1008  2019-07-08  2019-10-04        A2C  -0.104909  -0.200958    -0.12477\n",
       "15  1071  2019-10-04  2020-01-06        A2C      0.409   0.212395   -0.099511\n",
       "16  1134  2020-01-06  2020-04-06       DDPG  -0.372937  -0.347581    -0.26482\n",
       "17  1197  2020-04-06  2020-07-07       DDPG    0.17941   0.079824    0.274104\n",
       "18  1260  2020-07-07  2020-10-05       DDPG   0.017552  -0.013615    0.035169\n",
       "19  1323  2020-10-05  2021-01-05        A2C   0.330596   0.262684    0.055981"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.dump_session('17_year_sharpe_reward_dow.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2.585000</td>\n",
       "      <td>2.669643</td>\n",
       "      <td>2.580357</td>\n",
       "      <td>2.295634</td>\n",
       "      <td>807234400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.308567</td>\n",
       "      <td>2.289456</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.295634</td>\n",
       "      <td>2.295634</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>AXP</td>\n",
       "      <td>51.700001</td>\n",
       "      <td>52.580002</td>\n",
       "      <td>51.049999</td>\n",
       "      <td>41.155041</td>\n",
       "      <td>7825700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.308567</td>\n",
       "      <td>2.289456</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>41.155041</td>\n",
       "      <td>41.155041</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>BA</td>\n",
       "      <td>70.400002</td>\n",
       "      <td>70.599998</td>\n",
       "      <td>69.330002</td>\n",
       "      <td>50.119705</td>\n",
       "      <td>4943000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.308567</td>\n",
       "      <td>2.289456</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.119705</td>\n",
       "      <td>50.119705</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>CAT</td>\n",
       "      <td>57.869999</td>\n",
       "      <td>58.110001</td>\n",
       "      <td>57.049999</td>\n",
       "      <td>38.086823</td>\n",
       "      <td>3697500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.308567</td>\n",
       "      <td>2.289456</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>38.086823</td>\n",
       "      <td>38.086823</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>17.209999</td>\n",
       "      <td>17.490000</td>\n",
       "      <td>17.180000</td>\n",
       "      <td>12.956775</td>\n",
       "      <td>55426000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.308567</td>\n",
       "      <td>2.289456</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.956775</td>\n",
       "      <td>12.956775</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169139</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>V</td>\n",
       "      <td>233.100006</td>\n",
       "      <td>234.259995</td>\n",
       "      <td>232.130005</td>\n",
       "      <td>233.949997</td>\n",
       "      <td>4452500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.668748</td>\n",
       "      <td>233.608472</td>\n",
       "      <td>222.814534</td>\n",
       "      <td>58.710599</td>\n",
       "      <td>108.800722</td>\n",
       "      <td>30.377055</td>\n",
       "      <td>228.689480</td>\n",
       "      <td>224.125779</td>\n",
       "      <td>33.831745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169135</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>VZ</td>\n",
       "      <td>57.330002</td>\n",
       "      <td>57.610001</td>\n",
       "      <td>57.220001</td>\n",
       "      <td>57.340000</td>\n",
       "      <td>12013600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.144320</td>\n",
       "      <td>58.482470</td>\n",
       "      <td>55.706530</td>\n",
       "      <td>50.785631</td>\n",
       "      <td>-13.987824</td>\n",
       "      <td>0.130661</td>\n",
       "      <td>57.556333</td>\n",
       "      <td>57.430342</td>\n",
       "      <td>33.831745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169136</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>WBA</td>\n",
       "      <td>53.799999</td>\n",
       "      <td>55.580002</td>\n",
       "      <td>53.570000</td>\n",
       "      <td>55.310001</td>\n",
       "      <td>6638000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.242677</td>\n",
       "      <td>55.862549</td>\n",
       "      <td>52.305305</td>\n",
       "      <td>56.676743</td>\n",
       "      <td>75.341122</td>\n",
       "      <td>1.054941</td>\n",
       "      <td>53.905892</td>\n",
       "      <td>53.519815</td>\n",
       "      <td>33.831745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169137</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>WMT</td>\n",
       "      <td>139.080002</td>\n",
       "      <td>140.190002</td>\n",
       "      <td>139.080002</td>\n",
       "      <td>139.880005</td>\n",
       "      <td>5459500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.202702</td>\n",
       "      <td>143.623730</td>\n",
       "      <td>138.455272</td>\n",
       "      <td>50.613731</td>\n",
       "      <td>-58.482475</td>\n",
       "      <td>8.501810</td>\n",
       "      <td>140.619338</td>\n",
       "      <td>138.698263</td>\n",
       "      <td>33.831745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169138</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>XOM</td>\n",
       "      <td>63.610001</td>\n",
       "      <td>63.980000</td>\n",
       "      <td>62.250000</td>\n",
       "      <td>62.750000</td>\n",
       "      <td>27488700.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.060886</td>\n",
       "      <td>63.255273</td>\n",
       "      <td>57.322726</td>\n",
       "      <td>60.609907</td>\n",
       "      <td>148.516014</td>\n",
       "      <td>41.855094</td>\n",
       "      <td>60.011436</td>\n",
       "      <td>57.827412</td>\n",
       "      <td>33.831745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116580 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date   tic        open        high         low       close  \\\n",
       "0       2006-01-03  AAPL    2.585000    2.669643    2.580357    2.295634   \n",
       "1       2006-01-03   AXP   51.700001   52.580002   51.049999   41.155041   \n",
       "2       2006-01-03    BA   70.400002   70.599998   69.330002   50.119705   \n",
       "3       2006-01-03   CAT   57.869999   58.110001   57.049999   38.086823   \n",
       "4       2006-01-03  CSCO   17.209999   17.490000   17.180000   12.956775   \n",
       "...            ...   ...         ...         ...         ...         ...   \n",
       "169139  2021-06-10     V  233.100006  234.259995  232.130005  233.949997   \n",
       "169135  2021-06-10    VZ   57.330002   57.610001   57.220001   57.340000   \n",
       "169136  2021-06-10   WBA   53.799999   55.580002   53.570000   55.310001   \n",
       "169137  2021-06-10   WMT  139.080002  140.190002  139.080002  139.880005   \n",
       "169138  2021-06-10   XOM   63.610001   63.980000   62.250000   62.750000   \n",
       "\n",
       "             volume  day      macd     boll_ub     boll_lb      rsi_30  \\\n",
       "0       807234400.0  1.0  0.000000    2.308567    2.289456  100.000000   \n",
       "1         7825700.0  1.0  0.000000    2.308567    2.289456  100.000000   \n",
       "2         4943000.0  1.0  0.000000    2.308567    2.289456  100.000000   \n",
       "3         3697500.0  1.0  0.000000    2.308567    2.289456  100.000000   \n",
       "4        55426000.0  1.0  0.000000    2.308567    2.289456  100.000000   \n",
       "...             ...  ...       ...         ...         ...         ...   \n",
       "169139    4452500.0  3.0  1.668748  233.608472  222.814534   58.710599   \n",
       "169135   12013600.0  3.0 -0.144320   58.482470   55.706530   50.785631   \n",
       "169136    6638000.0  3.0  0.242677   55.862549   52.305305   56.676743   \n",
       "169137    5459500.0  3.0  0.202702  143.623730  138.455272   50.613731   \n",
       "169138   27488700.0  3.0  1.060886   63.255273   57.322726   60.609907   \n",
       "\n",
       "            cci_30       dx_30  close_30_sma  close_60_sma  turbulence  \n",
       "0        66.666667  100.000000      2.295634      2.295634    0.000000  \n",
       "1        66.666667  100.000000     41.155041     41.155041    0.000000  \n",
       "2        66.666667  100.000000     50.119705     50.119705    0.000000  \n",
       "3        66.666667  100.000000     38.086823     38.086823    0.000000  \n",
       "4        66.666667  100.000000     12.956775     12.956775    0.000000  \n",
       "...            ...         ...           ...           ...         ...  \n",
       "169139  108.800722   30.377055    228.689480    224.125779   33.831745  \n",
       "169135  -13.987824    0.130661     57.556333     57.430342   33.831745  \n",
       "169136   75.341122    1.054941     53.905892     53.519815   33.831745  \n",
       "169137  -58.482475    8.501810    140.619338    138.698263   33.831745  \n",
       "169138  148.516014   41.855094     60.011436     57.827412   33.831745  \n",
       "\n",
       "[116580 rows x 17 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('17_year_sharpe_reward_dow_df_summary.pkl', 'wb') as f:\n",
    "    pickle.dump(df_summary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('17_year_sharpe_reward_dow.pkl_processed_full', 'wb') as f:\n",
    "    pickle.dump(processed_full, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('17_year_sharpe_reward_dow_agent.pkl', 'wb') as f:\n",
    "    pickle.dump(ensemble_agent, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "uijiWgkuh1jB",
    "MRiOtrywfAo1",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "include_colab_link": true,
   "name": "FinRL_ensemble_stock_trading_ICAIF_2020.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "trading",
   "language": "python",
   "name": "trading"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
