{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-LLC/FinRL-Library/blob/master/FinRL_ensemble_stock_trading_ICAIF_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading Using Ensemble Strategy\n",
    "\n",
    "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
    "\n",
    "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
    "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
    "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mPT0ipYE28wL"
   },
   "outputs": [],
   "source": [
    "# ## install finrl library\n",
    "# !pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EeMK7Uentj1V"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lPqeTTwoh1hn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.config import config\n",
    "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "from finrl.model.models import DRLAgent,DRLEnsembleAgent\n",
    "from finrl.trade.backtest import get_baseline, backtest_stats, backtest_plot\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "87dea23f-469d-4e9d-de91-0f8a74929de2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2004-08-11'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py start_date is a string\n",
    "config.START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "d3baf63f-948a-49f9-f6f2-b7241971b8ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAPL', 'MSFT', 'JPM', 'RTX', 'PG', 'GS', 'NKE', 'DIS', 'AXP', 'HD', 'INTC', 'WMT', 'IBM', 'MRK', 'UNH', 'KO', 'CAT', 'TRV', 'JNJ', 'CVX', 'MCD', 'VZ', 'CSCO', 'XOM', 'BA', 'MMM', 'PFE', 'WBA', 'DD']\n"
     ]
    }
   ],
   "source": [
    "print(config.DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "932583d8-f98b-4243-c02d-375f7272db1a"
   },
   "outputs": [],
   "source": [
    "# from finrl.config.config import MISSING3\n",
    "# df = YahooDownloader(start_date = '2006-01-01',\n",
    "#                      end_date = '2021-06-11',\n",
    "#                      ticker_list = config.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.append(df2).append(df3).append(df4).append(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>2.585000</td>\n",
       "      <td>2.669643</td>\n",
       "      <td>2.580357</td>\n",
       "      <td>2.295634</td>\n",
       "      <td>807234400</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>51.700001</td>\n",
       "      <td>52.580002</td>\n",
       "      <td>51.049999</td>\n",
       "      <td>41.155041</td>\n",
       "      <td>7825700</td>\n",
       "      <td>AXP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>70.400002</td>\n",
       "      <td>70.599998</td>\n",
       "      <td>69.330002</td>\n",
       "      <td>50.119705</td>\n",
       "      <td>4943000</td>\n",
       "      <td>BA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>57.869999</td>\n",
       "      <td>58.110001</td>\n",
       "      <td>57.049999</td>\n",
       "      <td>38.086823</td>\n",
       "      <td>3697500</td>\n",
       "      <td>CAT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>17.209999</td>\n",
       "      <td>17.490000</td>\n",
       "      <td>17.180000</td>\n",
       "      <td>12.956775</td>\n",
       "      <td>55426000</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116020</th>\n",
       "      <td>116020</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>233.100006</td>\n",
       "      <td>234.259995</td>\n",
       "      <td>232.130005</td>\n",
       "      <td>233.949997</td>\n",
       "      <td>4452500</td>\n",
       "      <td>V</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116021</th>\n",
       "      <td>116021</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>57.330002</td>\n",
       "      <td>57.610001</td>\n",
       "      <td>57.220001</td>\n",
       "      <td>57.340000</td>\n",
       "      <td>12013600</td>\n",
       "      <td>VZ</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116022</th>\n",
       "      <td>116022</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>53.799999</td>\n",
       "      <td>55.580002</td>\n",
       "      <td>53.570000</td>\n",
       "      <td>55.310001</td>\n",
       "      <td>6638000</td>\n",
       "      <td>WBA</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116023</th>\n",
       "      <td>116023</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>139.080002</td>\n",
       "      <td>140.190002</td>\n",
       "      <td>139.080002</td>\n",
       "      <td>139.880005</td>\n",
       "      <td>5459500</td>\n",
       "      <td>WMT</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116024</th>\n",
       "      <td>116024</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>63.610001</td>\n",
       "      <td>63.980000</td>\n",
       "      <td>62.250000</td>\n",
       "      <td>62.750000</td>\n",
       "      <td>27488700</td>\n",
       "      <td>XOM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116025 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0        date        open        high         low  \\\n",
       "0                0  2006-01-03    2.585000    2.669643    2.580357   \n",
       "1                1  2006-01-03   51.700001   52.580002   51.049999   \n",
       "2                2  2006-01-03   70.400002   70.599998   69.330002   \n",
       "3                3  2006-01-03   57.869999   58.110001   57.049999   \n",
       "4                4  2006-01-03   17.209999   17.490000   17.180000   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "116020      116020  2021-06-10  233.100006  234.259995  232.130005   \n",
       "116021      116021  2021-06-10   57.330002   57.610001   57.220001   \n",
       "116022      116022  2021-06-10   53.799999   55.580002   53.570000   \n",
       "116023      116023  2021-06-10  139.080002  140.190002  139.080002   \n",
       "116024      116024  2021-06-10   63.610001   63.980000   62.250000   \n",
       "\n",
       "             close     volume   tic  day  \n",
       "0         2.295634  807234400  AAPL    1  \n",
       "1        41.155041    7825700   AXP    1  \n",
       "2        50.119705    4943000    BA    1  \n",
       "3        38.086823    3697500   CAT    1  \n",
       "4        12.956775   55426000  CSCO    1  \n",
       "...            ...        ...   ...  ...  \n",
       "116020  233.949997    4452500     V    3  \n",
       "116021   57.340000   12013600    VZ    3  \n",
       "116022   55.310001    6638000   WBA    3  \n",
       "116023  139.880005    5459500   WMT    3  \n",
       "116024   62.750000   27488700   XOM    3  \n",
       "\n",
       "[116025 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "# df.drop('Unnamed: 0')with open('dji_df_2004-2021.pkl', 'rb') as f:\n",
    "#     df = pickle.load(f)\n",
    "\n",
    "df = pd.read_csv('/home/roman/Work/trading-bot/notebooks/dji_prices_2020_04_09.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['date', 'tic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "GiRuFOTOtj1Y",
    "outputId": "bf7071db-d71a-4e1b-a28f-8e0145e0d204"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>2.585000</td>\n",
       "      <td>2.669643</td>\n",
       "      <td>2.580357</td>\n",
       "      <td>2.295634</td>\n",
       "      <td>807234400</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>51.700001</td>\n",
       "      <td>52.580002</td>\n",
       "      <td>51.049999</td>\n",
       "      <td>41.155041</td>\n",
       "      <td>7825700</td>\n",
       "      <td>AXP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>70.400002</td>\n",
       "      <td>70.599998</td>\n",
       "      <td>69.330002</td>\n",
       "      <td>50.119705</td>\n",
       "      <td>4943000</td>\n",
       "      <td>BA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>57.869999</td>\n",
       "      <td>58.110001</td>\n",
       "      <td>57.049999</td>\n",
       "      <td>38.086823</td>\n",
       "      <td>3697500</td>\n",
       "      <td>CAT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>17.209999</td>\n",
       "      <td>17.490000</td>\n",
       "      <td>17.180000</td>\n",
       "      <td>12.956775</td>\n",
       "      <td>55426000</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       open       high        low      close     volume   tic  \\\n",
       "0  2006-01-03   2.585000   2.669643   2.580357   2.295634  807234400  AAPL   \n",
       "1  2006-01-03  51.700001  52.580002  51.049999  41.155041    7825700   AXP   \n",
       "2  2006-01-03  70.400002  70.599998  69.330002  50.119705    4943000    BA   \n",
       "3  2006-01-03  57.869999  58.110001  57.049999  38.086823    3697500   CAT   \n",
       "4  2006-01-03  17.209999  17.490000  17.180000  12.956775   55426000  CSCO   \n",
       "\n",
       "   day  \n",
       "0    1  \n",
       "1    1  \n",
       "2    1  \n",
       "3    1  \n",
       "4    1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "DSw4ZEzVtj1Z",
    "outputId": "1a04171b-04c8-4974-9c63-3195261d8fd5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74625</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>155.630005</td>\n",
       "      <td>155.889999</td>\n",
       "      <td>153.929993</td>\n",
       "      <td>154.020004</td>\n",
       "      <td>900500</td>\n",
       "      <td>TRV</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74626</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>57.330002</td>\n",
       "      <td>57.610001</td>\n",
       "      <td>57.220001</td>\n",
       "      <td>57.340000</td>\n",
       "      <td>12013600</td>\n",
       "      <td>VZ</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74627</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>53.799999</td>\n",
       "      <td>55.580002</td>\n",
       "      <td>53.570000</td>\n",
       "      <td>55.310001</td>\n",
       "      <td>6638000</td>\n",
       "      <td>WBA</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74628</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>139.080002</td>\n",
       "      <td>140.190002</td>\n",
       "      <td>139.080002</td>\n",
       "      <td>139.880005</td>\n",
       "      <td>5459500</td>\n",
       "      <td>WMT</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74629</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>63.610001</td>\n",
       "      <td>63.980000</td>\n",
       "      <td>62.250000</td>\n",
       "      <td>62.750000</td>\n",
       "      <td>27488700</td>\n",
       "      <td>XOM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date        open        high         low       close    volume  \\\n",
       "74625  2021-06-10  155.630005  155.889999  153.929993  154.020004    900500   \n",
       "74626  2021-06-10   57.330002   57.610001   57.220001   57.340000  12013600   \n",
       "74627  2021-06-10   53.799999   55.580002   53.570000   55.310001   6638000   \n",
       "74628  2021-06-10  139.080002  140.190002  139.080002  139.880005   5459500   \n",
       "74629  2021-06-10   63.610001   63.980000   62.250000   62.750000  27488700   \n",
       "\n",
       "       tic  day  \n",
       "74625  TRV    3  \n",
       "74626   VZ    3  \n",
       "74627  WBA    3  \n",
       "74628  WMT    3  \n",
       "74629  XOM    3  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "b7b78172-8c8a-41c9-c8a6-0167edb9bd11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74630, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAPL', 'AXP', 'BA', 'CAT', 'CSCO', 'CVX', 'DD', 'DIS', 'GS', 'HD',\n",
       "       'IBM', 'INTC', 'JNJ', 'JPM', 'KO', 'MCD', 'MMM', 'MRK', 'MSFT',\n",
       "       'NKE', 'PFE', 'PG', 'RTX', 'TRV', 'UNH', 'VZ', 'WBA', 'WMT', 'XOM',\n",
       "       'V'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tic.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('dji_df_2004-2021.pkl', 'wb') as f:\n",
    "#     pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/roman/Work/trading-bot/notebooks/2004-2021_imputed_sentiment_final_df.pkl', 'rb') as f:\n",
    "    daily_sentiment_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>business_score</th>\n",
       "      <th>environment_score</th>\n",
       "      <th>politics_score</th>\n",
       "      <th>science_score</th>\n",
       "      <th>technology_score</th>\n",
       "      <th>world_score</th>\n",
       "      <th>business_magnitude</th>\n",
       "      <th>environment_magnitude</th>\n",
       "      <th>politics_magnitude</th>\n",
       "      <th>science_magnitude</th>\n",
       "      <th>technology_magnitude</th>\n",
       "      <th>world_magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-08-11</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>-0.366667</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>3.500</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>10.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-08-12</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.366667</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>-0.233333</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>15.433333</td>\n",
       "      <td>19.966667</td>\n",
       "      <td>5.300</td>\n",
       "      <td>10.066666</td>\n",
       "      <td>13.033334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-08-13</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.233334</td>\n",
       "      <td>5.300</td>\n",
       "      <td>2.266667</td>\n",
       "      <td>19.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-08-14</td>\n",
       "      <td>-0.233333</td>\n",
       "      <td>-0.233333</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>5.300</td>\n",
       "      <td>7.533334</td>\n",
       "      <td>13.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-08-15</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>13.733334</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>5.300</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>5.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6141</th>\n",
       "      <td>2021-06-07</td>\n",
       "      <td>-0.152000</td>\n",
       "      <td>-0.111765</td>\n",
       "      <td>-0.313043</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>-0.208333</td>\n",
       "      <td>-0.226000</td>\n",
       "      <td>15.572000</td>\n",
       "      <td>10.935294</td>\n",
       "      <td>18.982609</td>\n",
       "      <td>6.175</td>\n",
       "      <td>14.133333</td>\n",
       "      <td>21.184000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6142</th>\n",
       "      <td>2021-06-08</td>\n",
       "      <td>-0.213793</td>\n",
       "      <td>-0.085714</td>\n",
       "      <td>-0.310526</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-0.238000</td>\n",
       "      <td>14.465517</td>\n",
       "      <td>12.633334</td>\n",
       "      <td>25.405263</td>\n",
       "      <td>6.100</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>19.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6143</th>\n",
       "      <td>2021-06-09</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.084211</td>\n",
       "      <td>-0.256000</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.234000</td>\n",
       "      <td>15.242857</td>\n",
       "      <td>11.794737</td>\n",
       "      <td>27.012000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>8.875000</td>\n",
       "      <td>18.166000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6144</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>-0.118519</td>\n",
       "      <td>-0.107692</td>\n",
       "      <td>-0.213636</td>\n",
       "      <td>-0.080000</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-0.178000</td>\n",
       "      <td>14.151852</td>\n",
       "      <td>11.176923</td>\n",
       "      <td>23.786363</td>\n",
       "      <td>6.260</td>\n",
       "      <td>19.525000</td>\n",
       "      <td>17.912000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6145</th>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>-0.091667</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-0.158824</td>\n",
       "      <td>12.233334</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>19.412500</td>\n",
       "      <td>5.400</td>\n",
       "      <td>31.650001</td>\n",
       "      <td>17.029412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6149 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  business_score  environment_score  politics_score  \\\n",
       "0     2004-08-11       -0.033333          -0.366667       -0.133333   \n",
       "1     2004-08-12       -0.166667          -0.100000       -0.366667   \n",
       "2     2004-08-13       -0.300000          -0.100000       -0.066667   \n",
       "3     2004-08-14       -0.233333          -0.233333       -0.300000   \n",
       "4     2004-08-15       -0.100000          -0.333333       -0.300000   \n",
       "...          ...             ...                ...             ...   \n",
       "6141  2021-06-07       -0.152000          -0.111765       -0.313043   \n",
       "6142  2021-06-08       -0.213793          -0.085714       -0.310526   \n",
       "6143  2021-06-09       -0.200000          -0.084211       -0.256000   \n",
       "6144  2021-06-10       -0.118519          -0.107692       -0.213636   \n",
       "6145  2021-06-11       -0.091667          -0.150000       -0.187500   \n",
       "\n",
       "      science_score  technology_score  world_score  business_magnitude  \\\n",
       "0          0.066667         -0.033333    -0.333333            4.533333   \n",
       "1         -0.100000         -0.066667    -0.233333            5.166667   \n",
       "2         -0.100000         -0.133333    -0.100000            3.833333   \n",
       "3         -0.100000          0.033333    -0.200000            9.400000   \n",
       "4         -0.100000         -0.050000    -0.333333            8.600000   \n",
       "...             ...               ...          ...                 ...   \n",
       "6141      -0.050000         -0.208333    -0.226000           15.572000   \n",
       "6142      -0.133333         -0.285714    -0.238000           14.465517   \n",
       "6143      -0.150000         -0.200000    -0.234000           15.242857   \n",
       "6144      -0.080000         -0.150000    -0.178000           14.151852   \n",
       "6145      -0.050000         -0.150000    -0.158824           12.233334   \n",
       "\n",
       "      environment_magnitude  politics_magnitude  science_magnitude  \\\n",
       "0                  9.400000           17.900000              3.500   \n",
       "1                 15.433333           19.966667              5.300   \n",
       "2                 13.000000           13.233334              5.300   \n",
       "3                 10.600000           16.100000              5.300   \n",
       "4                 13.733334           19.200000              5.300   \n",
       "...                     ...                 ...                ...   \n",
       "6141              10.935294           18.982609              6.175   \n",
       "6142              12.633334           25.405263              6.100   \n",
       "6143              11.794737           27.012000              7.000   \n",
       "6144              11.176923           23.786363              6.260   \n",
       "6145              15.100000           19.412500              5.400   \n",
       "\n",
       "      technology_magnitude  world_magnitude  \n",
       "0                 4.900000        10.100000  \n",
       "1                10.066666        13.033334  \n",
       "2                 2.266667        19.966667  \n",
       "3                 7.533334        13.933333  \n",
       "4                 7.200000         5.166667  \n",
       "...                    ...              ...  \n",
       "6141             14.133333        21.184000  \n",
       "6142             12.400000        19.104000  \n",
       "6143              8.875000        18.166000  \n",
       "6144             19.525000        17.912000  \n",
       "6145             31.650001        17.029412  \n",
       "\n",
       "[6149 rows x 13 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "jgXfBcjxtj1a",
    "outputId": "abf8d5bb-2cd2-4c12-d4cb-ed1c429e60ce",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = config.TECHNICAL_INDICATORS_LIST,\n",
    "                    use_turbulence=True)\n",
    "\n",
    "processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'open',\n",
       " 'high',\n",
       " 'low',\n",
       " 'close',\n",
       " 'volume',\n",
       " 'tic',\n",
       " 'day',\n",
       " 'macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma',\n",
       " 'turbulence']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(processed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "R_3v-ycktj1b"
   },
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "grvhGJJII3Xn",
    "outputId": "91d09c37-b0e9-4c5c-d532-967e40d11f41"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145404</th>\n",
       "      <td>2019-04-11</td>\n",
       "      <td>UNH</td>\n",
       "      <td>246.050003</td>\n",
       "      <td>246.919998</td>\n",
       "      <td>232.679993</td>\n",
       "      <td>226.985260</td>\n",
       "      <td>8223400.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.950808</td>\n",
       "      <td>247.703096</td>\n",
       "      <td>229.131758</td>\n",
       "      <td>41.193396</td>\n",
       "      <td>-120.917290</td>\n",
       "      <td>34.839594</td>\n",
       "      <td>236.935162</td>\n",
       "      <td>245.672912</td>\n",
       "      <td>30.206898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56381</th>\n",
       "      <td>2011-02-25</td>\n",
       "      <td>INTC</td>\n",
       "      <td>21.520000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>21.459999</td>\n",
       "      <td>16.079168</td>\n",
       "      <td>53475700.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.095167</td>\n",
       "      <td>16.270748</td>\n",
       "      <td>15.492470</td>\n",
       "      <td>56.164736</td>\n",
       "      <td>77.443325</td>\n",
       "      <td>2.075169</td>\n",
       "      <td>15.754646</td>\n",
       "      <td>15.619415</td>\n",
       "      <td>26.364106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124973</th>\n",
       "      <td>2017-05-30</td>\n",
       "      <td>TRV</td>\n",
       "      <td>123.360001</td>\n",
       "      <td>124.230003</td>\n",
       "      <td>123.160004</td>\n",
       "      <td>111.790138</td>\n",
       "      <td>1139200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.542851</td>\n",
       "      <td>111.698529</td>\n",
       "      <td>107.366933</td>\n",
       "      <td>59.091724</td>\n",
       "      <td>206.565871</td>\n",
       "      <td>35.819800</td>\n",
       "      <td>109.403681</td>\n",
       "      <td>109.583163</td>\n",
       "      <td>20.428736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26478</th>\n",
       "      <td>2008-06-03</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>27.910000</td>\n",
       "      <td>28.309999</td>\n",
       "      <td>27.270000</td>\n",
       "      <td>20.466591</td>\n",
       "      <td>86616700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.296617</td>\n",
       "      <td>22.960626</td>\n",
       "      <td>20.394584</td>\n",
       "      <td>42.687388</td>\n",
       "      <td>-146.669316</td>\n",
       "      <td>20.872006</td>\n",
       "      <td>21.848735</td>\n",
       "      <td>21.691082</td>\n",
       "      <td>19.402154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13448</th>\n",
       "      <td>2007-03-27</td>\n",
       "      <td>GS</td>\n",
       "      <td>211.009995</td>\n",
       "      <td>211.729996</td>\n",
       "      <td>209.740005</td>\n",
       "      <td>172.573776</td>\n",
       "      <td>4806100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.606949</td>\n",
       "      <td>176.135296</td>\n",
       "      <td>156.423773</td>\n",
       "      <td>53.246927</td>\n",
       "      <td>33.933005</td>\n",
       "      <td>17.471910</td>\n",
       "      <td>169.790019</td>\n",
       "      <td>171.120632</td>\n",
       "      <td>16.541630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date   tic        open        high         low       close  \\\n",
       "145404  2019-04-11   UNH  246.050003  246.919998  232.679993  226.985260   \n",
       "56381   2011-02-25  INTC   21.520000   22.000000   21.459999   16.079168   \n",
       "124973  2017-05-30   TRV  123.360001  124.230003  123.160004  111.790138   \n",
       "26478   2008-06-03  MSFT   27.910000   28.309999   27.270000   20.466591   \n",
       "13448   2007-03-27    GS  211.009995  211.729996  209.740005  172.573776   \n",
       "\n",
       "            volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
       "145404   8223400.0  3.0 -1.950808  247.703096  229.131758  41.193396   \n",
       "56381   53475700.0  4.0  0.095167   16.270748   15.492470  56.164736   \n",
       "124973   1139200.0  1.0  0.542851  111.698529  107.366933  59.091724   \n",
       "26478   86616700.0  1.0 -0.296617   22.960626   20.394584  42.687388   \n",
       "13448    4806100.0  1.0  0.606949  176.135296  156.423773  53.246927   \n",
       "\n",
       "            cci_30      dx_30  close_30_sma  close_60_sma  turbulence  \n",
       "145404 -120.917290  34.839594    236.935162    245.672912   30.206898  \n",
       "56381    77.443325   2.075169     15.754646     15.619415   26.364106  \n",
       "124973  206.565871  35.819800    109.403681    109.583163   20.428736  \n",
       "26478  -146.669316  20.872006     21.848735     21.691082   19.402154  \n",
       "13448    33.933005  17.471910    169.790019    171.120632   16.541630  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2006-01-03'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full['date'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "187c6d1b-3e91-40f8-dafd-230d787f2ee1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.TECHNICAL_INDICATORS_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "8a2c943b-1be4-4b8d-b64f-666e0852b7e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 30, User Features: 0, State Space: 313\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(processed_full.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.TECHNICAL_INDICATORS_LIST)*stock_dimension + config.NUMBER_OF_DAILY_FEATURES\n",
    "print(f\"Stock Dimension: {stock_dimension}, User Features: {config.NUMBER_OF_USER_FEATURES}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 50_000_000/100, #Since in Indonesia the minimum number of shares per trx is 100, then we scaled the initial amount by dividing it with 100 \n",
    "    \"buy_cost_pct\": 0.0019, #IPOT has 0.19% buy cost\n",
    "    \"sell_cost_pct\": 0.0029, #IPOT has 0.29% sell cost\n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"print_verbosity\":5\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms.\n",
    "\n",
    "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "v-gthCxMtj1d"
   },
   "outputs": [],
   "source": [
    "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
    "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
    "train_start = '2006-01-03'\n",
    "train_end = '2016-01-01'\n",
    "val_test_start = '2016-01-01'\n",
    "val_test_end = '2021-06-11'\n",
    "\n",
    "ensemble_agent = DRLEnsembleAgent(df=processed_full,\n",
    "                 train_period=(train_start,train_end),\n",
    "                 val_test_period=(val_test_start,val_test_end),\n",
    "                 rebalance_window=rebalance_window, \n",
    "                 validation_window=validation_window,\n",
    "                 daily_features=daily_sentiment_df,\n",
    "                 **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "KsfEHa_Etj1d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A2C_model_kwargs = {\n",
    "                    'n_steps': 5,\n",
    "                    'ent_coef': 0.01,\n",
    "                    'learning_rate': 0.0005\n",
    "                    }\n",
    "\n",
    "PPO_model_kwargs = {\n",
    "                    \"ent_coef\":0.01,\n",
    "                    \"n_steps\": 2048,\n",
    "                    \"learning_rate\": 0.00025,\n",
    "                    \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "DDPG_model_kwargs = {\n",
    "                      \"action_noise\":\"ornstein_uhlenbeck\",\n",
    "                      \"buffer_size\": 50_000,\n",
    "                      \"learning_rate\": 0.000005,\n",
    "                      \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "timesteps_dict = {'a2c' : 100_000, \n",
    "                 'ppo' : 100_000, \n",
    "                 'ddpg' : 50_000\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1lyCECstj1e",
    "outputId": "72ac1ecc-909e-4d4c-d724-d906d7881ed9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Start Ensemble Strategy============\n",
      "============================================\n",
      "39.25064963834649\n",
      "turbulence_threshold:  458.4056541260132\n",
      "======Model training from:  2006-01-03 to  2016-01-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_126_16\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 156      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.104    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -30.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0386  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 15.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.465    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.00188 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 3.18     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0941   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 159      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -41.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -4.34    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+06 |\n",
      "|    total_cost         | 1.32e+05 |\n",
      "|    total_reward       | 5.58e+05 |\n",
      "|    total_reward_pct   | 112      |\n",
      "|    total_trades       | 52678    |\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0884   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -10.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.911    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 4.79     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.114    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.219    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 9.46     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.274    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 16.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.214    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.238   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -4.54    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.86e+05 |\n",
      "|    total_cost         | 1.89e+05 |\n",
      "|    total_reward       | 8.64e+04 |\n",
      "|    total_reward_pct   | 17.3     |\n",
      "|    total_trades       | 55353    |\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -1.1     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -47.4    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.0378  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -20.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.324    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.0875  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.103    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.043    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 33.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.99     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -8.06    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.321    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.94e+05 |\n",
      "|    total_cost         | 1.64e+05 |\n",
      "|    total_reward       | 2.94e+05 |\n",
      "|    total_reward_pct   | 58.8     |\n",
      "|    total_trades       | 53109    |\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.277    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 50.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.00417 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 34       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -16.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.00582  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -28.3    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.657    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 158       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | -103      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 5.58      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.09e+06  |\n",
      "|    total_cost         | 1.04e+05  |\n",
      "|    total_reward       | 5.85e+05  |\n",
      "|    total_reward_pct   | 117       |\n",
      "|    total_trades       | 48540     |\n",
      "| time/                 |           |\n",
      "|    fps                | 158       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 23.8      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.379     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -9.93    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.101    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 158       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | -0.000108 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 6.11      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.401     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.0776   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -23.2    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.015    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -363     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 78.4     |\n",
      "------------------------------------\n",
      "day: 2516, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1012025.14\n",
      "total_reward: 512025.14\n",
      "total_cost: 51615.92\n",
      "total_trades: 44227\n",
      "Sharpe: 0.489\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+06 |\n",
      "|    total_cost         | 5.16e+04 |\n",
      "|    total_reward       | 5.12e+05 |\n",
      "|    total_reward_pct   | 102      |\n",
      "|    total_trades       | 44227    |\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.0401   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 27       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.647    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 21.6     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.467    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.0153   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -45.9    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 6.34     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -21.9    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.389    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 66.1     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+06 |\n",
      "|    total_cost         | 2.17e+04 |\n",
      "|    total_reward       | 5.69e+05 |\n",
      "|    total_reward_pct   | 114      |\n",
      "|    total_trades       | 43989    |\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0.171    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -107     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 6.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0.242    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 46.9     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -11.3    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.197    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 156      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0.0691   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 65.9     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 3.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 155      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 8.7      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.625    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.76e+05 |\n",
      "|    total_cost         | 2.6e+04  |\n",
      "|    total_reward       | 3.76e+05 |\n",
      "|    total_reward_pct   | 75.1     |\n",
      "|    total_trades       | 45754    |\n",
      "| time/                 |          |\n",
      "|    fps                | 155      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0.378    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 39       |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.983    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 154      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | -0.584   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 49.4     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 154      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0.258    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 108      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 5.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 154      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | -0.244   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 18.6     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.327    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 153      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | -0.0528  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 13.9     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.733    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+06 |\n",
      "|    total_cost         | 7.46e+04 |\n",
      "|    total_reward       | 5.11e+05 |\n",
      "|    total_reward_pct   | 102      |\n",
      "|    total_trades       | 50857    |\n",
      "| time/                 |          |\n",
      "|    fps                | 153      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0.622    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 1.78     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.238    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 152       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 137       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.9     |\n",
      "|    explained_variance | -0.000533 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | 4.95      |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.303     |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0.567    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 16.4     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0.0339   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -31.6    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.635    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 152       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 147       |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.1     |\n",
      "|    explained_variance | -0.000562 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | -13.1     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.193     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.3e+05  |\n",
      "|    total_cost         | 1.76e+04 |\n",
      "|    total_reward       | 2.3e+05  |\n",
      "|    total_reward_pct   | 46       |\n",
      "|    total_trades       | 45470    |\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | -0.252   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -0.74    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.0756   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0.19     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 49.8     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.56     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | -0.0355  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 7.18     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.0984   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | -0.0359  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -35.7    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.616    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0.00304  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 14.8     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.158    |\n",
      "------------------------------------\n",
      "day: 2516, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 818406.44\n",
      "total_reward: 318406.44\n",
      "total_cost: 8138.48\n",
      "total_trades: 45384\n",
      "Sharpe: 0.336\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.18e+05 |\n",
      "|    total_cost         | 8.14e+03 |\n",
      "|    total_reward       | 3.18e+05 |\n",
      "|    total_reward_pct   | 63.7     |\n",
      "|    total_trades       | 45384    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | -0.00926 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 60.1     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 2.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 4.52     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.742    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 18.6     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.221    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | -0.0136  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -6.34    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.0677   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 2.98e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -10.5    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.435    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.35e+05 |\n",
      "|    total_cost         | 8.31e+03 |\n",
      "|    total_reward       | 2.35e+05 |\n",
      "|    total_reward_pct   | 47.1     |\n",
      "|    total_trades       | 43629    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -9.83    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.282    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -26      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.841    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -38.2    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.898    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 1.14     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.0242   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -78.5    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 3.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.11e+05 |\n",
      "|    total_cost         | 6.5e+03  |\n",
      "|    total_reward       | 3.11e+05 |\n",
      "|    total_reward_pct   | 62.1     |\n",
      "|    total_trades       | 43760    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0.114    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -86.6    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 6.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0.054    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 9.89     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.676    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -1.74    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.0501   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 13.2     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.163    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 216      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 56.8     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.28e+05 |\n",
      "|    total_cost         | 6e+03    |\n",
      "|    total_reward       | 2.28e+05 |\n",
      "|    total_reward_pct   | 45.6     |\n",
      "|    total_trades       | 44232    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | -0.102   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 19.7     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.275    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0.174    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -30.6    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.921    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -33.3    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.854    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 149       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 230       |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | 53.5      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 1.54      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 233      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0.113    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -87.4    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 4.24     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.31e+05 |\n",
      "|    total_cost         | 6.37e+03 |\n",
      "|    total_reward       | 2.31e+05 |\n",
      "|    total_reward_pct   | 46.3     |\n",
      "|    total_trades       | 45026    |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 237      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 2.99e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 43.8     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 1.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | -0.207   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 30       |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 1.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 244      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0.115    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -11.7    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.0788   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 247      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -33.6    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.72     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 250      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0.0475   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 80.9     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 4.38     |\n",
      "------------------------------------\n",
      "day: 2516, episode: 15\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 807188.69\n",
      "total_reward: 307188.69\n",
      "total_cost: 6943.23\n",
      "total_trades: 45356\n",
      "Sharpe: 0.327\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.07e+05 |\n",
      "|    total_cost         | 6.94e+03 |\n",
      "|    total_reward       | 3.07e+05 |\n",
      "|    total_reward_pct   | 61.4     |\n",
      "|    total_trades       | 45356    |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 254      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | -0.00173 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -4.67    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.0508   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 257      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -27.6    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.941    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 260      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 14.3     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.379    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0.198    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 31.8     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.581    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -1.91    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.0566   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.43e+05 |\n",
      "|    total_cost         | 5.41e+03 |\n",
      "|    total_reward       | 4.43e+05 |\n",
      "|    total_reward_pct   | 88.5     |\n",
      "|    total_trades       | 44348    |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 270      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.8    |\n",
      "|    explained_variance | 0.126    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 5.85     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0779   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 274      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0.134    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -48.6    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 1.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 277      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0.0917   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -5.53    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.165    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 149       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 280       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46       |\n",
      "|    explained_variance | -2.23e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | 8.04      |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.0736    |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 284      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 46.3     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 1.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.07e+05 |\n",
      "|    total_cost         | 6.51e+03 |\n",
      "|    total_reward       | 4.07e+05 |\n",
      "|    total_reward_pct   | 81.3     |\n",
      "|    total_trades       | 43022    |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 287      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46      |\n",
      "|    explained_variance | 0.0321   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 14.7     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.252    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 290      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -57      |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 2.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 294      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 2.39     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.0687   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 297      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 0.393    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | -9.04    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.102    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 300      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 0.171    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 54.3     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 1.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.27e+05 |\n",
      "|    total_cost         | 6.18e+03 |\n",
      "|    total_reward       | 4.27e+05 |\n",
      "|    total_reward_pct   | 85.4     |\n",
      "|    total_trades       | 40316    |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 304      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 0.786    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 17.3     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.138    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 307      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -66.8    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 2.93     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 149       |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 310       |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | -21.6     |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 0.266     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 313      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 0.235    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 5.97     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.194    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 317      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 0.386    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 13.9     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.108    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.92e+05 |\n",
      "|    total_cost         | 8.79e+03 |\n",
      "|    total_reward       | 3.92e+05 |\n",
      "|    total_reward_pct   | 78.4     |\n",
      "|    total_trades       | 41512    |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 320      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 0.125    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -10.6    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.118    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 323      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 0.165    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -26.3    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.333    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 149       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 327       |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | -19.1     |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 0.245     |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 331      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -17      |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.279    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 334      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | 0.274    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 19.3     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.346    |\n",
      "------------------------------------\n",
      "day: 2516, episode: 20\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 914963.52\n",
      "total_reward: 414963.52\n",
      "total_cost: 10448.99\n",
      "total_trades: 45884\n",
      "Sharpe: 0.420\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.15e+05 |\n",
      "|    total_cost         | 1.04e+04 |\n",
      "|    total_reward       | 4.15e+05 |\n",
      "|    total_reward_pct   | 83       |\n",
      "|    total_trades       | 45884    |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 338      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | -0.0692  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 12.5     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.0859   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 149       |\n",
      "|    iterations         | 10200     |\n",
      "|    time_elapsed       | 341       |\n",
      "|    total_timesteps    | 51000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10199     |\n",
      "|    policy_loss        | 46.5      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 1.6       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 149       |\n",
      "|    iterations         | 10300     |\n",
      "|    time_elapsed       | 345       |\n",
      "|    total_timesteps    | 51500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10299     |\n",
      "|    policy_loss        | 8.57      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 0.201     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 348      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0.0394   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | 42.7     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 1.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 352      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -17.9    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.245    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.26e+05 |\n",
      "|    total_cost         | 1.05e+04 |\n",
      "|    total_reward       | 4.26e+05 |\n",
      "|    total_reward_pct   | 85.3     |\n",
      "|    total_trades       | 44959    |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 355      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0.0797   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -9.16    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.229    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 358      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 54.5     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 1.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 362      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 77.7     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 3.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 365      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 9.68     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.371    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 369      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 4.48     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.0483   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+06    |\n",
      "|    total_cost         | 9.74e+03 |\n",
      "|    total_reward       | 5.01e+05 |\n",
      "|    total_reward_pct   | 100      |\n",
      "|    total_trades       | 45395    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 372      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -21.1    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.264    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 375      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0.0589   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | -63.5    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 2.32     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 379      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0.0309   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | 18.4     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.252    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 382      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | -0.723   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | 52.5     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 2.63     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 386      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0.298    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | 17.5     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.271    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.47e+05 |\n",
      "|    total_cost         | 1.32e+04 |\n",
      "|    total_reward       | 2.47e+05 |\n",
      "|    total_reward_pct   | 49.5     |\n",
      "|    total_trades       | 46470    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 389      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | 0.274    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 5.92     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.0721   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 393      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | -0.0144  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 45.4     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.942    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 396      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | 0.0241   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -56.3    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 2.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 400      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.2    |\n",
      "|    explained_variance | 0.21     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -46.8    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 1.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 403      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | -5.5     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.143    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.55e+05 |\n",
      "|    total_cost         | 1.46e+04 |\n",
      "|    total_reward       | 3.55e+05 |\n",
      "|    total_reward_pct   | 71       |\n",
      "|    total_trades       | 47982    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 407      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | 0.206    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 29.1     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.451    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 410      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | -12      |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 414      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | 0.0855   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 1.04     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.287    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 148       |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 417       |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | -45.5     |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 1.1       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 421      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 62.5     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 2.17     |\n",
      "------------------------------------\n",
      "day: 2516, episode: 25\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 973389.25\n",
      "total_reward: 473389.25\n",
      "total_cost: 13084.64\n",
      "total_trades: 45324\n",
      "Sharpe: 0.450\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.73e+05 |\n",
      "|    total_cost         | 1.31e+04 |\n",
      "|    total_reward       | 4.73e+05 |\n",
      "|    total_reward_pct   | 94.7     |\n",
      "|    total_trades       | 45324    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 424      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0.0369   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -10.3    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.123    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 427      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -35.7    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.536    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 431      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | -4.91    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.0849   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 434      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 2.5e-06  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 16.6     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 438      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0.0102   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -3.53    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.245    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.4e+05  |\n",
      "|    total_cost         | 1.29e+04 |\n",
      "|    total_reward       | 4.4e+05  |\n",
      "|    total_reward_pct   | 88.1     |\n",
      "|    total_trades       | 45379    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 441      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.6    |\n",
      "|    explained_variance | -0.135   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | 3.18     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.0719   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 444      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -18.3    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.484    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 448      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | 14.5     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.177    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 451      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -2.88    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.0073   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 148       |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 455       |\n",
      "|    total_timesteps    | 67500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | -24.7     |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 0.446     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.1e+06  |\n",
      "|    total_cost         | 1.14e+04 |\n",
      "|    total_reward       | 5.98e+05 |\n",
      "|    total_reward_pct   | 120      |\n",
      "|    total_trades       | 44721    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 458      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | -1.14    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.0227   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 462      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | -40.1    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.951    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 465      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.9    |\n",
      "|    explained_variance | 0.263    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | 39       |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.731    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 148       |\n",
      "|    iterations         | 13900     |\n",
      "|    time_elapsed       | 469       |\n",
      "|    total_timesteps    | 69500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13899     |\n",
      "|    policy_loss        | -2.1      |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 0.0339    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 472      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48      |\n",
      "|    explained_variance | -0.175   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | -45.6    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 2.09     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+06 |\n",
      "|    total_cost         | 7.92e+03 |\n",
      "|    total_reward       | 5.5e+05  |\n",
      "|    total_reward_pct   | 110      |\n",
      "|    total_trades       | 42847    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 476      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48      |\n",
      "|    explained_variance | 0.142    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | 15.9     |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.207    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 479      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.1    |\n",
      "|    explained_variance | 0.0933   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 31.7     |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.707    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 483      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | -100     |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 4.08     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 14400     |\n",
      "|    time_elapsed       | 486       |\n",
      "|    total_timesteps    | 72000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -48.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14399     |\n",
      "|    policy_loss        | -14.9     |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 0.135     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 489      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | -28      |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.355    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+06 |\n",
      "|    total_cost         | 6.56e+03 |\n",
      "|    total_reward       | 5.54e+05 |\n",
      "|    total_reward_pct   | 111      |\n",
      "|    total_trades       | 42166    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 493      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.2    |\n",
      "|    explained_variance | -0.532   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | -251     |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 37.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 496      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | -64.3    |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 2.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 500      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | 14.9     |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.176    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 503      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.3    |\n",
      "|    explained_variance | 0.532    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -32.1    |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.497    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 507      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.4    |\n",
      "|    explained_variance | 0.165    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | -28.9    |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.898    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 510      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.4    |\n",
      "|    explained_variance | 0.224    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | -11.8    |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.774    |\n",
      "------------------------------------\n",
      "day: 2516, episode: 30\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1089887.77\n",
      "total_reward: 589887.77\n",
      "total_cost: 4424.45\n",
      "total_trades: 40982\n",
      "Sharpe: 0.493\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.09e+06 |\n",
      "|    total_cost         | 4.42e+03 |\n",
      "|    total_reward       | 5.9e+05  |\n",
      "|    total_reward_pct   | 118      |\n",
      "|    total_trades       | 40982    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 514      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.5    |\n",
      "|    explained_variance | 0.483    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 48.3     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.993    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 517      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 12.5     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 521      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.5    |\n",
      "|    explained_variance | 0.139    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -108     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 5.9      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 524      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | 4.48     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 527      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | 0.65     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 1.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.6e+05  |\n",
      "|    total_cost         | 3.98e+03 |\n",
      "|    total_reward       | 4.6e+05  |\n",
      "|    total_reward_pct   | 91.9     |\n",
      "|    total_trades       | 38802    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 530      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.7    |\n",
      "|    explained_variance | 0.364    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | -53      |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 1.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 534      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 47       |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 1.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 537      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -36.6    |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 1.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 540      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.8    |\n",
      "|    explained_variance | -0.0171  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 38.1     |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.835    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 543      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | 69.2     |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 2.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+06 |\n",
      "|    total_cost         | 4.76e+03 |\n",
      "|    total_reward       | 5.23e+05 |\n",
      "|    total_reward_pct   | 105      |\n",
      "|    total_trades       | 38342    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 546      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -15.3    |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 549      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 18.2     |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.287    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 553      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 67.3     |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 2.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 556      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -69.8    |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 2.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 559      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -34.2    |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.941    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+06 |\n",
      "|    total_cost         | 4.38e+03 |\n",
      "|    total_reward       | 5.24e+05 |\n",
      "|    total_reward_pct   | 105      |\n",
      "|    total_trades       | 39610    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 562      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.1    |\n",
      "|    explained_variance | 0.00383  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | -19.4    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.176    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 565      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 30.5     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.562    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 569      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -32.9    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 1.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 572      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | 81.1     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 3.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 576      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -24.9    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 2.72     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.15e+06 |\n",
      "|    total_cost         | 3.66e+03 |\n",
      "|    total_reward       | 6.55e+05 |\n",
      "|    total_reward_pct   | 131      |\n",
      "|    total_trades       | 42276    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 579      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -7.16    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.233    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 148       |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 583       |\n",
      "|    total_timesteps    | 86500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | 20.5      |\n",
      "|    std                | 1.25      |\n",
      "|    value_loss         | 0.479     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 586      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | -99.6    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 4.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 590      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.3    |\n",
      "|    explained_variance | 0.0009   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -94.1    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 3.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 593      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -65.2    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 2.67     |\n",
      "------------------------------------\n",
      "day: 2516, episode: 35\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1055988.53\n",
      "total_reward: 555988.53\n",
      "total_cost: 3942.88\n",
      "total_trades: 44652\n",
      "Sharpe: 0.486\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+06 |\n",
      "|    total_cost         | 3.94e+03 |\n",
      "|    total_reward       | 5.56e+05 |\n",
      "|    total_reward_pct   | 111      |\n",
      "|    total_trades       | 44652    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 597      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.3    |\n",
      "|    explained_variance | 0.0388   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 10.7     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.241    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 600      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | 2.93     |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 0.0349   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 603      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | -34.3    |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 0.585    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 606      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 17.1     |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 0.177    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 148       |\n",
      "|    iterations         | 18100     |\n",
      "|    time_elapsed       | 610       |\n",
      "|    total_timesteps    | 90500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18099     |\n",
      "|    policy_loss        | 20.9      |\n",
      "|    std                | 1.26      |\n",
      "|    value_loss         | 0.72      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+06 |\n",
      "|    total_cost         | 4.49e+03 |\n",
      "|    total_reward       | 5.51e+05 |\n",
      "|    total_reward_pct   | 110      |\n",
      "|    total_trades       | 45252    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 613      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.5    |\n",
      "|    explained_variance | 0.383    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | 17.5     |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 0.198    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 617      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.6    |\n",
      "|    explained_variance | 0.143    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | -21.9    |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.454    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 620      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.6    |\n",
      "|    explained_variance | 0.256    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | 46.9     |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 1.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 624      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | 35.8     |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.718    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 627      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 35.4     |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.879    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.09e+06 |\n",
      "|    total_cost         | 3.54e+03 |\n",
      "|    total_reward       | 5.95e+05 |\n",
      "|    total_reward_pct   | 119      |\n",
      "|    total_trades       | 44258    |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 631      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | 14       |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.193    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 634      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -8.42    |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.0431   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 638      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.8    |\n",
      "|    explained_variance | 0.178    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -51      |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 1.78     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 641      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.8    |\n",
      "|    explained_variance | 0.179    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | -59.1    |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 2        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 645      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.8    |\n",
      "|    explained_variance | 1.55e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -38      |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 1        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.21e+06 |\n",
      "|    total_cost         | 3.29e+03 |\n",
      "|    total_reward       | 7.15e+05 |\n",
      "|    total_reward_pct   | 143      |\n",
      "|    total_trades       | 43253    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 648      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | -30.9    |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 0.372    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 652      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 38.4     |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 0.788    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 656      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | 11.1     |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 0.157    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 659      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 26.6     |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 0.532    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 663      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -15.3    |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 0.447    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.14e+06 |\n",
      "|    total_cost         | 4.09e+03 |\n",
      "|    total_reward       | 6.36e+05 |\n",
      "|    total_reward_pct   | 127      |\n",
      "|    total_trades       | 42981    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 666      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.2    |\n",
      "|    explained_variance | -0.0383  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | 1.12     |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 0.028    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 19800     |\n",
      "|    time_elapsed       | 670       |\n",
      "|    total_timesteps    | 99000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19799     |\n",
      "|    policy_loss        | 5.12      |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 0.269     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 19900     |\n",
      "|    time_elapsed       | 673       |\n",
      "|    total_timesteps    | 99500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19899     |\n",
      "|    policy_loss        | -21.7     |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 0.243     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 677      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 41.9     |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 1.16     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2016-01-04 to  2016-04-05\n",
      "A2C Sharpe Ratio:  0.1312844718900457\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_126_6\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 157  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 12   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 4.41e+05     |\n",
      "|    total_cost           | 4.06e+05     |\n",
      "|    total_reward         | -5.85e+04    |\n",
      "|    total_reward_pct     | -11.7        |\n",
      "|    total_trades         | 69248        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 154          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077474937 |\n",
      "|    clip_fraction        | 0.22         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | -0.0655      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.315        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0409      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.54         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.33e+05   |\n",
      "|    total_cost           | 3.89e+05   |\n",
      "|    total_reward         | -6.75e+04  |\n",
      "|    total_reward_pct     | -13.5      |\n",
      "|    total_trades         | 68258      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 156        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 39         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01911087 |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.6      |\n",
      "|    explained_variance   | 0.0464     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.00595    |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0452    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 1.17       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.47e+05    |\n",
      "|    total_cost           | 3.93e+05    |\n",
      "|    total_reward         | -5.26e+04   |\n",
      "|    total_reward_pct     | -10.5       |\n",
      "|    total_trades         | 68766       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024782088 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.127      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.127      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0463     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.85e+05    |\n",
      "|    total_cost           | 3.72e+05    |\n",
      "|    total_reward         | -1.15e+05   |\n",
      "|    total_reward_pct     | -23         |\n",
      "|    total_trades         | 67393       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015924864 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0669     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0476     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025378063 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.153      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.295      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0443     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.898       |\n",
      "-----------------------------------------\n",
      "day: 2516, episode: 45\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 452735.14\n",
      "total_reward: -47264.86\n",
      "total_cost: 386163.10\n",
      "total_trades: 67895\n",
      "Sharpe: 0.034\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.53e+05    |\n",
      "|    total_cost           | 3.86e+05    |\n",
      "|    total_reward         | -4.73e+04   |\n",
      "|    total_reward_pct     | -9.45       |\n",
      "|    total_trades         | 67895       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014367437 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.17       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0312     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0442     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.05        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.2e+05     |\n",
      "|    total_cost           | 3.74e+05    |\n",
      "|    total_reward         | -1.8e+05    |\n",
      "|    total_reward_pct     | -36.1       |\n",
      "|    total_trades         | 67477       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024424216 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.00393     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.142      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.946       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.87e+05    |\n",
      "|    total_cost           | 3.69e+05    |\n",
      "|    total_reward         | -1.13e+05   |\n",
      "|    total_reward_pct     | -22.6       |\n",
      "|    total_trades         | 66974       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028868865 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.0835     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.109      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.966       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.68e+05    |\n",
      "|    total_cost           | 3.91e+05    |\n",
      "|    total_reward         | 1.68e+05    |\n",
      "|    total_reward_pct     | 33.6        |\n",
      "|    total_trades         | 68192       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024304738 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0684      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0794      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037714675 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0228      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.085      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.04        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.51e+05    |\n",
      "|    total_cost           | 3.35e+05    |\n",
      "|    total_reward         | 1.51e+05    |\n",
      "|    total_reward_pct     | 30.3        |\n",
      "|    total_trades         | 65388       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033738595 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.0464     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.387       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.61        |\n",
      "-----------------------------------------\n",
      "day: 2516, episode: 50\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 557692.63\n",
      "total_reward: 57692.63\n",
      "total_cost: 332013.93\n",
      "total_trades: 64758\n",
      "Sharpe: 0.151\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.58e+05    |\n",
      "|    total_cost           | 3.32e+05    |\n",
      "|    total_reward         | 5.77e+04    |\n",
      "|    total_reward_pct     | 11.5        |\n",
      "|    total_trades         | 64758       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026039599 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.023      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.63e+05    |\n",
      "|    total_cost           | 2.94e+05    |\n",
      "|    total_reward         | -3.71e+04   |\n",
      "|    total_reward_pct     | -7.42       |\n",
      "|    total_trades         | 62413       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 178         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027929489 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.066      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0121      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.21e+05    |\n",
      "|    total_cost           | 3.14e+05    |\n",
      "|    total_reward         | 1.21e+05    |\n",
      "|    total_reward_pct     | 24.2        |\n",
      "|    total_trades         | 63699       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020219428 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0466      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0778      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.24        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.07e+05    |\n",
      "|    total_cost           | 3.42e+05    |\n",
      "|    total_reward         | 2.07e+05    |\n",
      "|    total_reward_pct     | 41.3        |\n",
      "|    total_trades         | 65348       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026867568 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0795      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.07        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 214         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022071082 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.277       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 1.66        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.67e+05    |\n",
      "|    total_cost           | 2.98e+05    |\n",
      "|    total_reward         | 6.69e+04    |\n",
      "|    total_reward_pct     | 13.4        |\n",
      "|    total_trades         | 62802       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 226         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016523505 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0338      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0867     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 1.18        |\n",
      "-----------------------------------------\n",
      "day: 2516, episode: 55\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 849003.63\n",
      "total_reward: 349003.63\n",
      "total_cost: 293523.28\n",
      "total_trades: 62265\n",
      "Sharpe: 0.374\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.49e+05    |\n",
      "|    total_cost           | 2.94e+05    |\n",
      "|    total_reward         | 3.49e+05    |\n",
      "|    total_reward_pct     | 69.8        |\n",
      "|    total_trades         | 62265       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 239         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032976046 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0277      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.287       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 1.56        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.07e+05    |\n",
      "|    total_cost           | 2.96e+05    |\n",
      "|    total_reward         | 4.07e+05    |\n",
      "|    total_reward_pct     | 81.4        |\n",
      "|    total_trades         | 62354       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 251         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011403477 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.327       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 1.91        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.27e+05    |\n",
      "|    total_cost           | 3.64e+05    |\n",
      "|    total_reward         | 2.68e+04    |\n",
      "|    total_reward_pct     | 5.37        |\n",
      "|    total_trades         | 66901       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 263         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030386532 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.216       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 1.47        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 163        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 276        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04463406 |\n",
      "|    clip_fraction        | 0.43       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.105      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0685    |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0269    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.761      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.55e+05    |\n",
      "|    total_cost           | 3.01e+05    |\n",
      "|    total_reward         | 3.55e+05    |\n",
      "|    total_reward_pct     | 71          |\n",
      "|    total_trades         | 62650       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 163         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027694795 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.327       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 1.42        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.67e+05    |\n",
      "|    total_cost           | 3.26e+05    |\n",
      "|    total_reward         | 1.67e+05    |\n",
      "|    total_reward_pct     | 33.5        |\n",
      "|    total_trades         | 63808       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 163         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 300         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036180846 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.262       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 1.46        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2516, episode: 60\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 490199.71\n",
      "total_reward: -9800.29\n",
      "total_cost: 342726.61\n",
      "total_trades: 64501\n",
      "Sharpe: 0.074\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.9e+05     |\n",
      "|    total_cost           | 3.43e+05    |\n",
      "|    total_reward         | -9.8e+03    |\n",
      "|    total_reward_pct     | -1.96       |\n",
      "|    total_trades         | 64501       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 163         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 312         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035490323 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0868      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 1.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.56e+05    |\n",
      "|    total_cost           | 3.09e+05    |\n",
      "|    total_reward         | 4.56e+05    |\n",
      "|    total_reward_pct     | 91.3        |\n",
      "|    total_trades         | 63079       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 324         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054029018 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | -0.0592     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.034       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 1.18        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 164        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 336        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04401285 |\n",
      "|    clip_fraction        | 0.329      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.177      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.211      |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 1.34       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 1.03e+06  |\n",
      "|    total_cost           | 3.31e+05  |\n",
      "|    total_reward         | 5.34e+05  |\n",
      "|    total_reward_pct     | 107       |\n",
      "|    total_trades         | 64110     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 164       |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 348       |\n",
      "|    total_timesteps      | 57344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0311489 |\n",
      "|    clip_fraction        | 0.28      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -44.2     |\n",
      "|    explained_variance   | 0.191     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 0.631     |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | -0.0168   |\n",
      "|    std                  | 1.06      |\n",
      "|    value_loss           | 2.06      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.48e+05    |\n",
      "|    total_cost           | 2.65e+05    |\n",
      "|    total_reward         | 4.48e+05    |\n",
      "|    total_reward_pct     | 89.6        |\n",
      "|    total_trades         | 60451       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 361         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035449788 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.119       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 1.48        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.27e+05    |\n",
      "|    total_cost           | 3.07e+05    |\n",
      "|    total_reward         | 3.27e+05    |\n",
      "|    total_reward_pct     | 65.4        |\n",
      "|    total_trades         | 62703       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 373         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026788235 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.51        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 1.68        |\n",
      "-----------------------------------------\n",
      "day: 2516, episode: 65\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 765837.54\n",
      "total_reward: 265837.54\n",
      "total_cost: 294424.80\n",
      "total_trades: 62115\n",
      "Sharpe: 0.322\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.66e+05   |\n",
      "|    total_cost           | 2.94e+05   |\n",
      "|    total_reward         | 2.66e+05   |\n",
      "|    total_reward_pct     | 53.2       |\n",
      "|    total_trades         | 62115      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 164        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 385        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04491569 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.265      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.0835     |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0237    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 1.27       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.36e+05    |\n",
      "|    total_cost           | 2.69e+05    |\n",
      "|    total_reward         | 3.36e+05    |\n",
      "|    total_reward_pct     | 67.2        |\n",
      "|    total_trades         | 60271       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 397         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042471897 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0372      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 409         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027280852 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0977      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 1.27        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 7.89e+05  |\n",
      "|    total_cost           | 2.66e+05  |\n",
      "|    total_reward         | 2.89e+05  |\n",
      "|    total_reward_pct     | 57.8      |\n",
      "|    total_trades         | 60142     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 165       |\n",
      "|    iterations           | 34        |\n",
      "|    time_elapsed         | 421       |\n",
      "|    total_timesteps      | 69632     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0326093 |\n",
      "|    clip_fraction        | 0.244     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -44.7     |\n",
      "|    explained_variance   | 0.496     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 0.103     |\n",
      "|    n_updates            | 330       |\n",
      "|    policy_gradient_loss | -0.0205   |\n",
      "|    std                  | 1.07      |\n",
      "|    value_loss           | 1.28      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.64e+05    |\n",
      "|    total_cost           | 2.61e+05    |\n",
      "|    total_reward         | 4.64e+05    |\n",
      "|    total_reward_pct     | 92.8        |\n",
      "|    total_trades         | 58844       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 433         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020674935 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.278       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 1.35        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.69e+05    |\n",
      "|    total_cost           | 3.03e+05    |\n",
      "|    total_reward         | 4.69e+05    |\n",
      "|    total_reward_pct     | 93.8        |\n",
      "|    total_trades         | 62174       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 446         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045832664 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.188       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 1.57        |\n",
      "-----------------------------------------\n",
      "day: 2516, episode: 70\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 945299.11\n",
      "total_reward: 445299.11\n",
      "total_cost: 272828.63\n",
      "total_trades: 59878\n",
      "Sharpe: 0.422\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.45e+05    |\n",
      "|    total_cost           | 2.73e+05    |\n",
      "|    total_reward         | 4.45e+05    |\n",
      "|    total_reward_pct     | 89.1        |\n",
      "|    total_trades         | 59878       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 458         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036398727 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.203       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 1.65        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 471         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021744404 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.163       |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 1.32        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.04e+06    |\n",
      "|    total_cost           | 2.74e+05    |\n",
      "|    total_reward         | 5.44e+05    |\n",
      "|    total_reward_pct     | 109         |\n",
      "|    total_trades         | 60407       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 484         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030860242 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.335       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 1.93        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.43e+05    |\n",
      "|    total_cost           | 3.15e+05    |\n",
      "|    total_reward         | 3.43e+05    |\n",
      "|    total_reward_pct     | 68.5        |\n",
      "|    total_trades         | 61863       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 496         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032230884 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.151       |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 1.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.8e+05     |\n",
      "|    total_cost           | 3.2e+05     |\n",
      "|    total_reward         | 7.99e+04    |\n",
      "|    total_reward_pct     | 16          |\n",
      "|    total_trades         | 63466       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 509         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041402627 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.485       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 1.72        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.16e+05   |\n",
      "|    total_cost           | 3e+05      |\n",
      "|    total_reward         | 4.16e+05   |\n",
      "|    total_reward_pct     | 83.1       |\n",
      "|    total_trades         | 62611      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 164        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 522        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04240474 |\n",
      "|    clip_fraction        | 0.354      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.1      |\n",
      "|    explained_variance   | -0.0342    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.131     |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.027     |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 1.24       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 535         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046845257 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.017       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 1.33        |\n",
      "-----------------------------------------\n",
      "day: 2516, episode: 75\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 733165.53\n",
      "total_reward: 233165.53\n",
      "total_cost: 357264.76\n",
      "total_trades: 64965\n",
      "Sharpe: 0.296\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.33e+05   |\n",
      "|    total_cost           | 3.57e+05   |\n",
      "|    total_reward         | 2.33e+05   |\n",
      "|    total_reward_pct     | 46.6       |\n",
      "|    total_trades         | 64965      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 164        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 547        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06931086 |\n",
      "|    clip_fraction        | 0.415      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.3      |\n",
      "|    explained_variance   | 0.0105     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.402      |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.00826   |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 1.71       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.66e+06    |\n",
      "|    total_cost           | 2.13e+05    |\n",
      "|    total_reward         | 1.16e+06    |\n",
      "|    total_reward_pct     | 233         |\n",
      "|    total_trades         | 55818       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 560         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019226797 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.521       |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 2.38        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.67e+05    |\n",
      "|    total_cost           | 3.43e+05    |\n",
      "|    total_reward         | -1.33e+05   |\n",
      "|    total_reward_pct     | -26.7       |\n",
      "|    total_trades         | 64448       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 572         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053191025 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.794       |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.73e+05   |\n",
      "|    total_cost           | 3.84e+05   |\n",
      "|    total_reward         | -2.66e+04  |\n",
      "|    total_reward_pct     | -5.33      |\n",
      "|    total_trades         | 66439      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 164        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 585        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08169272 |\n",
      "|    clip_fraction        | 0.455      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.5      |\n",
      "|    explained_variance   | 0.197      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.24       |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 1.28       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.16e+05   |\n",
      "|    total_cost           | 3.52e+05   |\n",
      "|    total_reward         | 2.16e+05   |\n",
      "|    total_reward_pct     | 43.2       |\n",
      "|    total_trades         | 64315      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 164        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 597        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06532981 |\n",
      "|    clip_fraction        | 0.435      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.6      |\n",
      "|    explained_variance   | 0.0855     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.24      |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.022     |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 0.799      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 609         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049999803 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | -0.0727     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0608      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 1.47        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2016-01-04 to  2016-04-05\n",
      "PPO Sharpe Ratio:  0.16490591312130673\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_126_6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.02e+06 |\n",
      "|    total_cost       | 1.37e+03 |\n",
      "|    total_reward     | 5.2e+05  |\n",
      "|    total_reward_pct | 104      |\n",
      "|    total_trades     | 29740    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total timesteps  | 10068    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -7.42    |\n",
      "|    critic_loss      | 2.48     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7551     |\n",
      "----------------------------------\n",
      "day: 2516, episode: 85\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1103667.99\n",
      "total_reward: 603667.99\n",
      "total_cost: 1480.64\n",
      "total_trades: 24279\n",
      "Sharpe: 0.460\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.04e+06 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | 5.43e+05 |\n",
      "|    total_reward_pct | 109      |\n",
      "|    total_trades     | 30909    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 108      |\n",
      "|    time_elapsed     | 185      |\n",
      "|    total timesteps  | 20136    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -8.97    |\n",
      "|    critic_loss      | 1.56     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 17619    |\n",
      "----------------------------------\n",
      "day: 2516, episode: 90\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1041915.27\n",
      "total_reward: 541915.27\n",
      "total_cost: 951.54\n",
      "total_trades: 29729\n",
      "Sharpe: 0.442\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.04e+06 |\n",
      "|    total_cost       | 1.06e+03 |\n",
      "|    total_reward     | 5.39e+05 |\n",
      "|    total_reward_pct | 108      |\n",
      "|    total_trades     | 29744    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 105      |\n",
      "|    time_elapsed     | 286      |\n",
      "|    total timesteps  | 30204    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -8.25    |\n",
      "|    critic_loss      | 2.36     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 27687    |\n",
      "----------------------------------\n",
      "day: 2516, episode: 95\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1036270.16\n",
      "total_reward: 536270.16\n",
      "total_cost: 1300.61\n",
      "total_trades: 31580\n",
      "Sharpe: 0.429\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.05e+06 |\n",
      "|    total_cost       | 1.81e+03 |\n",
      "|    total_reward     | 5.53e+05 |\n",
      "|    total_reward_pct | 111      |\n",
      "|    total_trades     | 26259    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 103      |\n",
      "|    time_elapsed     | 387      |\n",
      "|    total timesteps  | 40272    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -6.82    |\n",
      "|    critic_loss      | 7.34     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 37755    |\n",
      "----------------------------------\n",
      "day: 2516, episode: 100\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1086168.40\n",
      "total_reward: 586168.40\n",
      "total_cost: 1834.12\n",
      "total_trades: 38420\n",
      "Sharpe: 0.440\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.09e+06 |\n",
      "|    total_cost       | 1.83e+03 |\n",
      "|    total_reward     | 5.86e+05 |\n",
      "|    total_reward_pct | 117      |\n",
      "|    total_trades     | 38420    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 103      |\n",
      "|    time_elapsed     | 487      |\n",
      "|    total timesteps  | 50340    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -5.17    |\n",
      "|    critic_loss      | 4.37     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 47823    |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2016-01-04 to  2016-04-05\n",
      "======Best Model Retraining from:  2006-01-03 to  2016-04-05\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ensemble_126_4\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 171  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 11   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.13e+05    |\n",
      "|    total_cost           | 4.38e+05    |\n",
      "|    total_reward         | 1.29e+04    |\n",
      "|    total_reward_pct     | 2.57        |\n",
      "|    total_trades         | 71975       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 169         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019031024 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.105      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.295       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.64        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.75e+05    |\n",
      "|    total_cost           | 4.11e+05    |\n",
      "|    total_reward         | 7.48e+04    |\n",
      "|    total_reward_pct     | 15          |\n",
      "|    total_trades         | 70340       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 167         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011634698 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.125      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.144       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0459     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.47        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.87e+05   |\n",
      "|    total_cost           | 4.08e+05   |\n",
      "|    total_reward         | -1.13e+05  |\n",
      "|    total_reward_pct     | -22.6      |\n",
      "|    total_trades         | 70350      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 166        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 49         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01788669 |\n",
      "|    clip_fraction        | 0.198      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | -0.166     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0066    |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0386    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.42       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 166         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018600963 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.118      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0467     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.049      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.961       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.62e+05    |\n",
      "|    total_cost           | 4.26e+05    |\n",
      "|    total_reward         | 6.24e+04    |\n",
      "|    total_reward_pct     | 12.5        |\n",
      "|    total_trades         | 70894       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 166         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014018025 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0564     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.312       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0418     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.99        |\n",
      "-----------------------------------------\n",
      "day: 2579, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 456333.55\n",
      "total_reward: -43666.45\n",
      "total_cost: 401053.88\n",
      "total_trades: 69981\n",
      "Sharpe: 0.047\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.56e+05    |\n",
      "|    total_cost           | 4.01e+05    |\n",
      "|    total_reward         | -4.37e+04   |\n",
      "|    total_reward_pct     | -8.73       |\n",
      "|    total_trades         | 69981       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 166         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015518891 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.0493     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0675      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0443     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.49        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.89e+05    |\n",
      "|    total_cost           | 4.08e+05    |\n",
      "|    total_reward         | 8.87e+04    |\n",
      "|    total_reward_pct     | 17.7        |\n",
      "|    total_trades         | 70535       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 166         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025228307 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.171       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.59        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.18e+05    |\n",
      "|    total_cost           | 4.11e+05    |\n",
      "|    total_reward         | 2.18e+05    |\n",
      "|    total_reward_pct     | 43.5        |\n",
      "|    total_trades         | 70250       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 166         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016147025 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0637      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.229       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.7         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018724844 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0943      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.232       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.66        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.19e+05    |\n",
      "|    total_cost           | 3.96e+05    |\n",
      "|    total_reward         | -1.81e+05   |\n",
      "|    total_reward_pct     | -36.2       |\n",
      "|    total_trades         | 69612       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 163         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 137         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021619765 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | -0.0686     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0429      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.8e+05     |\n",
      "|    total_cost           | 3.62e+05    |\n",
      "|    total_reward         | -2.2e+05    |\n",
      "|    total_reward_pct     | -44         |\n",
      "|    total_trades         | 67493       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029382255 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.0526     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.08       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0442     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.908       |\n",
      "-----------------------------------------\n",
      "day: 2579, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 336714.65\n",
      "total_reward: -163285.35\n",
      "total_cost: 376214.47\n",
      "total_trades: 68526\n",
      "Sharpe: -0.074\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.37e+05    |\n",
      "|    total_cost           | 3.76e+05    |\n",
      "|    total_reward         | -1.63e+05   |\n",
      "|    total_reward_pct     | -32.7       |\n",
      "|    total_trades         | 68526       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 163         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044111803 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | -0.283      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00561    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.2         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.43e+05   |\n",
      "|    total_cost           | 4.03e+05   |\n",
      "|    total_reward         | 4.31e+04   |\n",
      "|    total_reward_pct     | 8.61       |\n",
      "|    total_trades         | 69820      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 162        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 176        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03183069 |\n",
      "|    clip_fraction        | 0.372      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.0589     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.0795     |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0403    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 1.17       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047532253 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0353      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0341     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.14        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 5.23e+05  |\n",
      "|    total_cost           | 4.01e+05  |\n",
      "|    total_reward         | 2.3e+04   |\n",
      "|    total_reward_pct     | 4.61      |\n",
      "|    total_trades         | 69188     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 161       |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 202       |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0381336 |\n",
      "|    clip_fraction        | 0.303     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.6     |\n",
      "|    explained_variance   | 0.113     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 0.369     |\n",
      "|    n_updates            | 150       |\n",
      "|    policy_gradient_loss | -0.0368   |\n",
      "|    std                  | 1.04      |\n",
      "|    value_loss           | 1.78      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.24e+05   |\n",
      "|    total_cost           | 4.04e+05   |\n",
      "|    total_reward         | 2.42e+04   |\n",
      "|    total_reward_pct     | 4.83       |\n",
      "|    total_trades         | 69684      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 161        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 215        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03004739 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | 0.0449     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.0796     |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0374    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 1.33       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.73e+05    |\n",
      "|    total_cost           | 3.92e+05    |\n",
      "|    total_reward         | 7.3e+04     |\n",
      "|    total_reward_pct     | 14.6        |\n",
      "|    total_trades         | 69333       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 227         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038114555 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0681      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.117       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 1.39        |\n",
      "-----------------------------------------\n",
      "day: 2579, episode: 15\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 709951.83\n",
      "total_reward: 209951.83\n",
      "total_cost: 381417.72\n",
      "total_trades: 68724\n",
      "Sharpe: 0.266\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.1e+05     |\n",
      "|    total_cost           | 3.81e+05    |\n",
      "|    total_reward         | 2.1e+05     |\n",
      "|    total_reward_pct     | 42          |\n",
      "|    total_trades         | 68724       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 240         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032631833 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.019       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0406     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 1.29        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 162        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 252        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03148319 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | -0.0213    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.243      |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0255    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 2.18       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.16e+05   |\n",
      "|    total_cost           | 3.71e+05   |\n",
      "|    total_reward         | 1.56e+04   |\n",
      "|    total_reward_pct     | 3.11       |\n",
      "|    total_trades         | 67999      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 162        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 265        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03069587 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | -0.085     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.254      |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0327    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 1.89       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.66e+05    |\n",
      "|    total_cost           | 3.96e+05    |\n",
      "|    total_reward         | 1.66e+05    |\n",
      "|    total_reward_pct     | 33.2        |\n",
      "|    total_trades         | 68888       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 278         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028119074 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | -0.00327    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.461       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 1.86        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.9e+05    |\n",
      "|    total_cost           | 3.58e+05   |\n",
      "|    total_reward         | -1.02e+04  |\n",
      "|    total_reward_pct     | -2.04      |\n",
      "|    total_trades         | 67147      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 161        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 291        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05428914 |\n",
      "|    clip_fraction        | 0.352      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | -0.0896    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.509      |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0335    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 2.02       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.11e+05    |\n",
      "|    total_cost           | 3.8e+05     |\n",
      "|    total_reward         | -8.94e+04   |\n",
      "|    total_reward_pct     | -17.9       |\n",
      "|    total_trades         | 67281       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 303         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042339258 |\n",
      "|    clip_fraction        | 0.39        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | -0.0202     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.111      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 1.07        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 315         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028456382 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.095       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.334       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 1.4         |\n",
      "-----------------------------------------\n",
      "day: 2579, episode: 20\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 607424.10\n",
      "total_reward: 107424.10\n",
      "total_cost: 391338.75\n",
      "total_trades: 68631\n",
      "Sharpe: 0.195\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.07e+05    |\n",
      "|    total_cost           | 3.91e+05    |\n",
      "|    total_reward         | 1.07e+05    |\n",
      "|    total_reward_pct     | 21.5        |\n",
      "|    total_trades         | 68631       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 327         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026244687 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.05        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0445     |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 1.27        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.38e+05    |\n",
      "|    total_cost           | 3.41e+05    |\n",
      "|    total_reward         | 3.78e+04    |\n",
      "|    total_reward_pct     | 7.55        |\n",
      "|    total_trades         | 66616       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 340         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032495238 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0571      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.272       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 1.31        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.37e+05    |\n",
      "|    total_cost           | 3.17e+05    |\n",
      "|    total_reward         | 3.65e+04    |\n",
      "|    total_reward_pct     | 7.31        |\n",
      "|    total_trades         | 64576       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033089533 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 5.1e-05     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.165       |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 1.71        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.54e+05    |\n",
      "|    total_cost           | 3.76e+05    |\n",
      "|    total_reward         | 2.54e+05    |\n",
      "|    total_reward_pct     | 50.8        |\n",
      "|    total_trades         | 67857       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029486652 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.127       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 1.53        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 162       |\n",
      "|    iterations           | 30        |\n",
      "|    time_elapsed         | 377       |\n",
      "|    total_timesteps      | 61440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0317267 |\n",
      "|    clip_fraction        | 0.34      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -44.8     |\n",
      "|    explained_variance   | 0.0912    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 0.498     |\n",
      "|    n_updates            | 290       |\n",
      "|    policy_gradient_loss | -0.0299   |\n",
      "|    std                  | 1.08      |\n",
      "|    value_loss           | 2.32      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.57e+05    |\n",
      "|    total_cost           | 3.21e+05    |\n",
      "|    total_reward         | 5.67e+04    |\n",
      "|    total_reward_pct     | 11.3        |\n",
      "|    total_trades         | 64654       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 390         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034162477 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0291      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.566       |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 2.11        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2579, episode: 25\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 532207.91\n",
      "total_reward: 32207.91\n",
      "total_cost: 318777.41\n",
      "total_trades: 64550\n",
      "Sharpe: 0.146\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.32e+05    |\n",
      "|    total_cost           | 3.19e+05    |\n",
      "|    total_reward         | 3.22e+04    |\n",
      "|    total_reward_pct     | 6.44        |\n",
      "|    total_trades         | 64550       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 403         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034775224 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.143       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.616       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 2.32        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.1e+05     |\n",
      "|    total_cost           | 3.79e+05    |\n",
      "|    total_reward         | 1.01e+04    |\n",
      "|    total_reward_pct     | 2.02        |\n",
      "|    total_trades         | 67395       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 415         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035324037 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.0437      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.407       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 1.81        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 162       |\n",
      "|    iterations           | 34        |\n",
      "|    time_elapsed         | 428       |\n",
      "|    total_timesteps      | 69632     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0581698 |\n",
      "|    clip_fraction        | 0.42      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -45.1     |\n",
      "|    explained_variance   | -0.0141   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.0803   |\n",
      "|    n_updates            | 330       |\n",
      "|    policy_gradient_loss | -0.0283   |\n",
      "|    std                  | 1.09      |\n",
      "|    value_loss           | 0.942     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.26e+05    |\n",
      "|    total_cost           | 3.23e+05    |\n",
      "|    total_reward         | 2.63e+04    |\n",
      "|    total_reward_pct     | 5.27        |\n",
      "|    total_trades         | 65155       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 441         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035149887 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.1         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.352       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 2.06        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.05e+05    |\n",
      "|    total_cost           | 3.02e+05    |\n",
      "|    total_reward         | 5.43e+03    |\n",
      "|    total_reward_pct     | 1.09        |\n",
      "|    total_trades         | 63761       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 453         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029934818 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | -0.0396     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.248       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 2.08        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.5e+05     |\n",
      "|    total_cost           | 3.06e+05    |\n",
      "|    total_reward         | 4.95e+04    |\n",
      "|    total_reward_pct     | 9.91        |\n",
      "|    total_trades         | 63858       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 466         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030505322 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.772       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 2.65        |\n",
      "-----------------------------------------\n",
      "day: 2579, episode: 30\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 509135.38\n",
      "total_reward: 9135.38\n",
      "total_cost: 293252.17\n",
      "total_trades: 63088\n",
      "Sharpe: 0.137\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.09e+05   |\n",
      "|    total_cost           | 2.93e+05   |\n",
      "|    total_reward         | 9.14e+03   |\n",
      "|    total_reward_pct     | 1.83       |\n",
      "|    total_trades         | 63088      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 162        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 478        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03157638 |\n",
      "|    clip_fraction        | 0.282      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.3      |\n",
      "|    explained_variance   | -0.0589    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.609      |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.021     |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 2.37       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 490         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036037263 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.121       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 1.76        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.73e+05    |\n",
      "|    total_cost           | 2.77e+05    |\n",
      "|    total_reward         | -2.68e+04   |\n",
      "|    total_reward_pct     | -5.36       |\n",
      "|    total_trades         | 62182       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 502         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028300587 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.0313      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.827       |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.27e+05    |\n",
      "|    total_cost           | 2.83e+05    |\n",
      "|    total_reward         | 2.66e+04    |\n",
      "|    total_reward_pct     | 5.32        |\n",
      "|    total_trades         | 62005       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 515         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026956845 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 3.42        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.03e+05    |\n",
      "|    total_cost           | 2.74e+05    |\n",
      "|    total_reward         | 1.03e+05    |\n",
      "|    total_reward_pct     | 20.5        |\n",
      "|    total_trades         | 62671       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 528         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025682239 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.787       |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 2.66        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.3e+05     |\n",
      "|    total_cost           | 2.11e+05    |\n",
      "|    total_reward         | 2.3e+05     |\n",
      "|    total_reward_pct     | 46.1        |\n",
      "|    total_trades         | 58878       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 540         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017482009 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.1         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 3.35        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 552         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027804462 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.0583      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 3.77        |\n",
      "-----------------------------------------\n",
      "day: 2579, episode: 35\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 578556.83\n",
      "total_reward: 78556.83\n",
      "total_cost: 219102.86\n",
      "total_trades: 59517\n",
      "Sharpe: 0.194\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.79e+05    |\n",
      "|    total_cost           | 2.19e+05    |\n",
      "|    total_reward         | 7.86e+04    |\n",
      "|    total_reward_pct     | 15.7        |\n",
      "|    total_trades         | 59517       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 565         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018291483 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | -0.0497     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 3.38        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.47e+05   |\n",
      "|    total_cost           | 2.56e+05   |\n",
      "|    total_reward         | 4.69e+04   |\n",
      "|    total_reward_pct     | 9.39       |\n",
      "|    total_trades         | 60962      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 162        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 578        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02611285 |\n",
      "|    clip_fraction        | 0.249      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.6      |\n",
      "|    explained_variance   | 0.117      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.766      |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0209    |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 3.05       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.06e+05    |\n",
      "|    total_cost           | 2.67e+05    |\n",
      "|    total_reward         | 1.06e+05    |\n",
      "|    total_reward_pct     | 21.2        |\n",
      "|    total_trades         | 61332       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 591         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034311004 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.793       |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 2.89        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.65e+05    |\n",
      "|    total_cost           | 2.76e+05    |\n",
      "|    total_reward         | 1.65e+05    |\n",
      "|    total_reward_pct     | 33.1        |\n",
      "|    total_trades         | 61666       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 603         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041971773 |\n",
      "|    clip_fraction        | 0.437       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | 0.0729      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.225       |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 1.76        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 162        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 616        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04747367 |\n",
      "|    clip_fraction        | 0.386      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.8      |\n",
      "|    explained_variance   | 0.000574   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.0914     |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0127    |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 1.34       |\n",
      "----------------------------------------\n",
      "======Trading from:  2016-04-05 to  2016-07-05\n",
      "============================================\n",
      "44.0092241400934\n",
      "turbulence_threshold:  458.4056541260132\n",
      "======Model training from:  2006-01-03 to  2016-04-05\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_189_5\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.246    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -51.5    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.95     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.229   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 8.83     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.199    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 143      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -48.6    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -20.5    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.315    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -0.000641 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 14.8      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.235     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.93e+05 |\n",
      "|    total_cost         | 1.58e+05 |\n",
      "|    total_reward       | 2.93e+05 |\n",
      "|    total_reward_pct   | 58.6     |\n",
      "|    total_trades       | 57128    |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.22     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -36      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.844    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0056  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 51.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.67     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 149       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 37        |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.28      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 149       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 30        |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.67e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 28        |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.631     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -10.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.222    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.34e+05 |\n",
      "|    total_cost         | 1.18e+05 |\n",
      "|    total_reward       | 3.34e+05 |\n",
      "|    total_reward_pct   | 66.8     |\n",
      "|    total_trades       | 50747    |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0973   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 18.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.216    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0582   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -3.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.102    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 1.78     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 86.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -47.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.14e+06 |\n",
      "|    total_cost         | 2.66e+04 |\n",
      "|    total_reward       | 6.41e+05 |\n",
      "|    total_reward_pct   | 128      |\n",
      "|    total_trades       | 42337    |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 2.09e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -6.97    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0628   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 59.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 2.34     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0532   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.0788  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -39      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.35     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 151       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 45.3      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.97      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.21e+06 |\n",
      "|    total_cost         | 1.36e+04 |\n",
      "|    total_reward       | 7.1e+05  |\n",
      "|    total_reward_pct   | 142      |\n",
      "|    total_trades       | 40975    |\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0.716    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 28.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.407    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 151       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | 53.4      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.16      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 72.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -63.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 27       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.447    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2579, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1189949.37\n",
      "total_reward: 689949.37\n",
      "total_cost: 8000.54\n",
      "total_trades: 42296\n",
      "Sharpe: 0.520\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.19e+06 |\n",
      "|    total_cost         | 8e+03    |\n",
      "|    total_reward       | 6.9e+05  |\n",
      "|    total_reward_pct   | 138      |\n",
      "|    total_trades       | 42296    |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.0637   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -20.3    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.451    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 28.9     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.442    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 152       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 91        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 10.6      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.597     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 20.4     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.338    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -9.12    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.117    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.12e+06 |\n",
      "|    total_cost         | 6.11e+03 |\n",
      "|    total_reward       | 6.17e+05 |\n",
      "|    total_reward_pct   | 123      |\n",
      "|    total_trades       | 40306    |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -1.54    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 21.3     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.346    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0.0895   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -138     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 10.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 152       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | -4.89e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 20.5      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.58      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -38.2    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -62.3    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -5.09    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.115    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.17e+06  |\n",
      "|    total_cost         | 8.28e+03  |\n",
      "|    total_reward       | 6.7e+05   |\n",
      "|    total_reward_pct   | 134       |\n",
      "|    total_trades       | 37097     |\n",
      "| time/                 |           |\n",
      "|    fps                | 152       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 121       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 16.7      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.185     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -10      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.159    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 2.84     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.7      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | -0.497   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 37.1     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -69.2    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 3.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.21e+06 |\n",
      "|    total_cost         | 1.01e+04 |\n",
      "|    total_reward       | 7.14e+05 |\n",
      "|    total_reward_pct   | 143      |\n",
      "|    total_trades       | 37211    |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 4.59     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.109    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -10.3    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.163    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 152       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 144       |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | -2.62     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.0452    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | -0.0111  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 38.6     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 22.8     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.366    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.24e+06 |\n",
      "|    total_cost         | 8.91e+03 |\n",
      "|    total_reward       | 7.42e+05 |\n",
      "|    total_reward_pct   | 148      |\n",
      "|    total_trades       | 38074    |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -4.84    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.0236   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -53.2    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -8.25    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.0957   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -31.7    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.678    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -17.4    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.5      |\n",
      "------------------------------------\n",
      "day: 2579, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1209758.06\n",
      "total_reward: 709758.06\n",
      "total_cost: 9200.43\n",
      "total_trades: 38311\n",
      "Sharpe: 0.564\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.21e+06 |\n",
      "|    total_cost         | 9.2e+03  |\n",
      "|    total_reward       | 7.1e+05  |\n",
      "|    total_reward_pct   | 142      |\n",
      "|    total_trades       | 38311    |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -20.1    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.271    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -199     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 18.4     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 11.1     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.105    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -71.3    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 2.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -4.01    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.305    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.32e+06 |\n",
      "|    total_cost         | 8.93e+03 |\n",
      "|    total_reward       | 8.21e+05 |\n",
      "|    total_reward_pct   | 164      |\n",
      "|    total_trades       | 40226    |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | -0.236   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -10      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.168    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -29.4    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.651    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -33      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -110     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 6.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 21.6     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.261    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.27e+06 |\n",
      "|    total_cost         | 1.21e+04 |\n",
      "|    total_reward       | 7.68e+05 |\n",
      "|    total_reward_pct   | 154      |\n",
      "|    total_trades       | 37511    |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | -576     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 31.5     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 2.68     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 152       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 206       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | 5.34      |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.0837    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 152       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 210       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.9     |\n",
      "|    explained_variance | -3.85e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 5.36      |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.207     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 32.2     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.641    |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()# print([self.state[0]])\n",
    "        # print(self.data.close.values.tolist())\n",
    "        # print(list(self.state[(self.stock_dim+1):(self.stock_dim*2+1)]))\n",
    "        # print(sum([self.data[tech].values.tolist() for tech in self.tech_indicator_list ], []) )\n",
    "        # user_features_columns = self.data.columns[-config.NUMBER_OF_USER_FEATURES:]\n",
    "        # print(self.data[user_features_columns].values[0])\n",
    "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs, PPO_model_kwargs, DDPG_model_kwargs, timesteps_dict)\n",
    "time_elapsed = time.time()-start\n",
    "print(time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "-0qd8acMtj1f",
    "outputId": "a7fa85f0-7825-4b9a-d313-cd99ad70ecb0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter</th>\n",
       "      <th>Val Start</th>\n",
       "      <th>Val End</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>A2C Sharpe</th>\n",
       "      <th>PPO Sharpe</th>\n",
       "      <th>DDPG Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.127394</td>\n",
       "      <td>0.303177</td>\n",
       "      <td>0.264977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.12121</td>\n",
       "      <td>-0.002137</td>\n",
       "      <td>0.070818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.042202</td>\n",
       "      <td>-0.045131</td>\n",
       "      <td>0.151223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.573297</td>\n",
       "      <td>0.566399</td>\n",
       "      <td>0.705078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.122285</td>\n",
       "      <td>-0.138578</td>\n",
       "      <td>-0.031246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>441</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>2017-07-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.150122</td>\n",
       "      <td>0.098266</td>\n",
       "      <td>0.268507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>504</td>\n",
       "      <td>2017-07-05</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.30975</td>\n",
       "      <td>0.240212</td>\n",
       "      <td>0.113961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>567</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.832907</td>\n",
       "      <td>0.487907</td>\n",
       "      <td>0.633911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>630</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.038953</td>\n",
       "      <td>-0.120097</td>\n",
       "      <td>-0.115019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>693</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>2018-07-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.208591</td>\n",
       "      <td>-0.177387</td>\n",
       "      <td>0.055126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>756</td>\n",
       "      <td>2018-07-05</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.466436</td>\n",
       "      <td>0.24904</td>\n",
       "      <td>0.486105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>819</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.302995</td>\n",
       "      <td>-0.419185</td>\n",
       "      <td>-0.196341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>882</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.165556</td>\n",
       "      <td>0.545425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>945</td>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.080163</td>\n",
       "      <td>-0.035117</td>\n",
       "      <td>0.19109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1008</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.042706</td>\n",
       "      <td>-0.256371</td>\n",
       "      <td>-0.160446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1071</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.470853</td>\n",
       "      <td>0.38627</td>\n",
       "      <td>0.561674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1134</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.215682</td>\n",
       "      <td>-0.263877</td>\n",
       "      <td>-0.130965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1197</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.125179</td>\n",
       "      <td>0.074876</td>\n",
       "      <td>0.119182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1260</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.007387</td>\n",
       "      <td>0.041112</td>\n",
       "      <td>0.132897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1323</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.311107</td>\n",
       "      <td>0.176215</td>\n",
       "      <td>0.338129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
       "0    126  2016-01-04  2016-04-05        PPO   0.127394   0.303177    0.264977\n",
       "1    189  2016-04-05  2016-07-05        A2C    0.12121  -0.002137    0.070818\n",
       "2    252  2016-07-05  2016-10-03       DDPG  -0.042202  -0.045131    0.151223\n",
       "3    315  2016-10-03  2017-01-03       DDPG   0.573297   0.566399    0.705078\n",
       "4    378  2017-01-03  2017-04-04       DDPG  -0.122285  -0.138578   -0.031246\n",
       "5    441  2017-04-04  2017-07-05       DDPG   0.150122   0.098266    0.268507\n",
       "6    504  2017-07-05  2017-10-03        A2C    0.30975   0.240212    0.113961\n",
       "7    567  2017-10-03  2018-01-03        A2C   0.832907   0.487907    0.633911\n",
       "8    630  2018-01-03  2018-04-05        A2C  -0.038953  -0.120097   -0.115019\n",
       "9    693  2018-04-05  2018-07-05       DDPG  -0.208591  -0.177387    0.055126\n",
       "10   756  2018-07-05  2018-10-03       DDPG   0.466436    0.24904    0.486105\n",
       "11   819  2018-10-03  2019-01-04       DDPG  -0.302995  -0.419185   -0.196341\n",
       "12   882  2019-01-04  2019-04-05       DDPG   0.435897   0.165556    0.545425\n",
       "13   945  2019-04-05  2019-07-08       DDPG  -0.080163  -0.035117     0.19109\n",
       "14  1008  2019-07-08  2019-10-04        A2C  -0.042706  -0.256371   -0.160446\n",
       "15  1071  2019-10-04  2020-01-06       DDPG   0.470853    0.38627    0.561674\n",
       "16  1134  2020-01-06  2020-04-06       DDPG  -0.215682  -0.263877   -0.130965\n",
       "17  1197  2020-04-06  2020-07-07        A2C   0.125179   0.074876    0.119182\n",
       "18  1260  2020-07-07  2020-10-05       DDPG  -0.007387   0.041112    0.132897\n",
       "19  1323  2020-10-05  2021-01-05       DDPG   0.311107   0.176215    0.338129"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-5475607d3df5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fe' is not defined"
     ]
    }
   ],
   "source": [
    "del fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'finrl.preprocessing.preprocessors.FeatureEngineer'>: it's not the same object as finrl.preprocessing.preprocessors.FeatureEngineer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-a16226672779>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdill\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdill\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'17_year_guardian_sentiment_fixed_fixed_dow.db'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/dill/_dill.py\u001b[0m in \u001b[0;36mdump_session\u001b[0;34m(filename, main, byref, **kwds)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recurse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;31m# disable pickling recursion for globals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# is best indicator of when pickling a session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# If newly opened file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/dill/_dill.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mPicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0mStockPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m         \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# clear record of 'recursion-sensitive' pickled objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/dill/_dill.py\u001b[0m in \u001b[0;36msave_module\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 + [\"__builtins__\", \"__loader__\"]]\n\u001b[1;32m   1326\u001b[0m             pickler.save_reduce(_import_module, (obj.__name__,), obj=obj,\n\u001b[0;32m-> 1327\u001b[0;31m                                 state=_main_dict)\n\u001b[0m\u001b[1;32m   1328\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"# M1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/dill/_dill.py\u001b[0m in \u001b[0;36msave_module_dict\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0;31m# we only care about session the first pass thru\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m         \u001b[0mStockPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"# D2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    883\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/dill/_dill.py\u001b[0m in \u001b[0;36msave_type\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1388\u001b[0m        \u001b[0;31m#print (\"%s\\n%s\" % (obj.__bases__, obj.__dict__))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__qualname__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0mStockPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_global\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"# T4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_global\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m    963\u001b[0m                 raise PicklingError(\n\u001b[1;32m    964\u001b[0m                     \u001b[0;34m\"Can't pickle %r: it's not the same object as %s.%s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                     (obj, module_name, name))\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class 'finrl.preprocessing.preprocessors.FeatureEngineer'>: it's not the same object as finrl.preprocessing.preprocessors.FeatureEngineer"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "dill.dump_session('17_year_guardian_sentiment_fixed_fixed_dow.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('sentiment_1.pkl', 'wb') as f:\n",
    "    pickle.dump(processed_full, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('17_year_guardian_sentiment_fixed_fixed_dow_df_summary.pkl', 'wb') as f:\n",
    "    pickle.dump(df_summary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('17_year_guardian_sentiment_fixed_fixed_dow_processed_full.pkl', 'wb') as f:\n",
    "    pickle.dump(processed_full, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'finrl.env.env_stocktrading.StockTradingEnv'>: it's not the same object as finrl.env.env_stocktrading.StockTradingEnv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-80640691c27e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'17_year_guardian_sentiment_fixed_fixed_dow_ensemble_agent.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensemble_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class 'finrl.env.env_stocktrading.StockTradingEnv'>: it's not the same object as finrl.env.env_stocktrading.StockTradingEnv"
     ]
    }
   ],
   "source": [
    "with open('17_year_guardian_sentiment_fixed_fixed_dow_ensemble_agent.pkl', 'wb') as f:\n",
    "    pickle.dump(ensemble_agent, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "uijiWgkuh1jB",
    "MRiOtrywfAo1",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "include_colab_link": true,
   "name": "FinRL_ensemble_stock_trading_ICAIF_2020.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "finrl",
   "language": "python",
   "name": "finrl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
